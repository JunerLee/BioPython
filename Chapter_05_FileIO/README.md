# Chapter 05: æ–‡ä»¶IOä¸FASTAå¤„ç† - ä½ çš„æ•°å­—å®éªŒè®°å½•æœ¬

## ğŸ“Œ å†™åœ¨æœ€å‰é¢ - ç»™ç”Ÿç‰©å­¦ç ”ç©¶è€…çš„ä¸€å°ä¿¡

äº²çˆ±çš„ç ”ç©¶è€…ï¼š

è¿˜è®°å¾—ä½ ç¬¬ä¸€æ¬¡åœ¨å®éªŒå®¤è®°å½•å®éªŒæ•°æ®æ—¶çš„æƒ…æ™¯å—ï¼Ÿä½ å°å¿ƒç¿¼ç¿¼åœ°æ‰“å¼€å®éªŒè®°å½•æœ¬ï¼Œå·¥æ•´åœ°å†™ä¸‹æ—¥æœŸã€å®éªŒæ¡ä»¶ã€è§‚å¯Ÿç»“æœ...æ¯ä¸€ä¸ªæ•°æ®éƒ½æ˜¯ä½ è¾›è‹¦å®éªŒçš„æˆæœï¼Œæ¯ä¸€é¡µè®°å½•éƒ½è§è¯ç€ä½ çš„ç§‘ç ”å†ç¨‹ã€‚

åœ¨è®¡ç®—æœºçš„ä¸–ç•Œé‡Œï¼Œæ–‡ä»¶å°±æ˜¯æˆ‘ä»¬çš„**æ•°å­—å®éªŒè®°å½•æœ¬**ã€‚è€Œä»Šå¤©ï¼Œæˆ‘è¦æ•™ä½ å¦‚ä½•ç”¨Pythonæ¥ç®¡ç†è¿™äº›æ•°å­—è®°å½•æœ¬â€”â€”ä¸ä»…èƒ½è®°å½•æ•°æ®ï¼Œè¿˜èƒ½è‡ªåŠ¨æ•´ç†ã€åˆ†æï¼Œç”šè‡³å¸®ä½ å‘ç°é‚£äº›äººçœ¼å®¹æ˜“å¿½ç•¥çš„è§„å¾‹ã€‚

æ›´é‡è¦çš„æ˜¯ï¼Œä½ å°†å­¦ä¼šå¤„ç†FASTAæ ¼å¼â€”â€”è¿™ä¸ªåœ¨ç”Ÿç‰©ä¿¡æ¯å­¦é¢†åŸŸæ— å¤„ä¸åœ¨çš„åºåˆ—æ ¼å¼ã€‚æ— è®ºæ˜¯ä»NCBIä¸‹è½½çš„åŸºå› åºåˆ—ï¼Œè¿˜æ˜¯æµ‹åºå…¬å¸å‘æ¥çš„åŸå§‹æ•°æ®ï¼ŒæŒæ¡FASTAæ–‡ä»¶çš„å¤„ç†å°±åƒæŒæ¡äº†æ‰“å¼€åŸºå› å¯†ç å®åº“çš„é’¥åŒ™ã€‚

è®©æˆ‘ä»¬å¼€å§‹è¿™æ®µæ¿€åŠ¨äººå¿ƒçš„å­¦ä¹ ä¹‹æ—…ï¼

## ğŸ“š æœ¬ç« å¯¼èˆª

```python
å­¦ä¹ è·¯çº¿å›¾ = {
    "ç¬¬ä¸€ç«™": "ç†è§£æ–‡ä»¶çš„æœ¬è´¨ - ä¸ºä»€ä¹ˆéœ€è¦æŒä¹…åŒ–å­˜å‚¨",
    "ç¬¬äºŒç«™": "æ–‡ä»¶æ“ä½œåŸºç¡€ - æ‰“å¼€ã€è¯»å–ã€å†™å…¥ã€å…³é—­",
    "ç¬¬ä¸‰ç«™": "æ–‡ä»¶ç³»ç»Ÿå¯¼èˆª - è·¯å¾„ã€ç›®å½•ã€æ–‡ä»¶ç®¡ç†",
    "ç¬¬å››ç«™": "æ–‡æœ¬ç¼–ç è§£å¯† - UTF-8ã€ASCIIåŠå…¶é‡è¦æ€§",
    "ç¬¬äº”ç«™": "FASTAæ ¼å¼è¯¦è§£ - ç”Ÿç‰©ä¿¡æ¯å­¦çš„é€šç”¨è¯­è¨€",
    "ç¬¬å…­ç«™": "é€æ­¥æ„å»ºè§£æå™¨ - ä»ç®€å•åˆ°ä¸“ä¸š",
    "ç¬¬ä¸ƒç«™": "å¤§æ–‡ä»¶å¤„ç†ç­–ç•¥ - å¤„ç†åŸºå› ç»„çº§æ•°æ®",
    "ç¬¬å…«ç«™": "é”™è¯¯å¤„ç†è‰ºæœ¯ - è®©ç¨‹åºç¨³å¦‚æ³°å±±",
    "ç¬¬ä¹ç«™": "å®æˆ˜é¡¹ç›® - æ„å»ºåºåˆ—åˆ†ææµç¨‹",
    "ç¬¬åç«™": "æ€§èƒ½ä¼˜åŒ– - è®©ç¨‹åºé£èµ·æ¥"
}
```

## ğŸ¯ å­¦ä¹ ç›®æ ‡

å®Œæˆæœ¬ç« å­¦ä¹ åï¼Œä½ å°†èƒ½å¤Ÿï¼š

1. **æ–‡ä»¶æ“ä½œè‡ªå¦‚**
   - åƒä½¿ç”¨å®éªŒè®°å½•æœ¬ä¸€æ ·è‡ªç„¶åœ°æ“ä½œæ–‡ä»¶
   - ç†è§£æ–‡ä»¶ç³»ç»Ÿçš„ç»„ç»‡ç»“æ„
   - æŒæ¡å„ç§æ–‡ä»¶æ“ä½œæ¨¡å¼

2. **FASTAæ ¼å¼ç²¾é€š**
   - æ·±å…¥ç†è§£FASTAæ ¼å¼çš„è®¾è®¡å“²å­¦
   - èƒ½å¤Ÿè§£æå„ç§å˜ä½“çš„FASTAæ–‡ä»¶
   - ä¼šç”Ÿæˆæ ‡å‡†çš„FASTAæ ¼å¼è¾“å‡º

3. **å¤§æ•°æ®å¤„ç†**
   - å¤„ç†GBçº§åˆ«çš„åŸºå› ç»„æ–‡ä»¶
   - ä½¿ç”¨ç”Ÿæˆå™¨ä¼˜åŒ–å†…å­˜ä½¿ç”¨
   - å®ç°æµå¼å¤„ç†pipeline

4. **ä¸“ä¸šçº§ç¼–ç¨‹**
   - å®Œå–„çš„é”™è¯¯å¤„ç†æœºåˆ¶
   - æ¨¡å—åŒ–çš„ä»£ç è®¾è®¡
   - å¯é‡ç”¨çš„å·¥å…·å‡½æ•°

## ğŸ”¬ ç¬¬ä¸€éƒ¨åˆ†ï¼šä¸ºä»€ä¹ˆéœ€è¦æ–‡ä»¶æ“ä½œï¼Ÿ

### çœŸå®åœºæ™¯1ï¼šPCRäº§ç‰©æµ‹åºç»“æœ

```python
"""
åœºæ™¯ï¼šä½ åˆšå®Œæˆäº†ä¸€ä¸ªé‡è¦åŸºå› çš„PCRæ‰©å¢ï¼Œæµ‹åºå…¬å¸å‘æ¥äº†ç»“æœã€‚
å¦‚æœä¸ä¿å­˜ä¸‹æ¥ï¼Œå…³é—­ç¨‹åºåæ‰€æœ‰æ•°æ®éƒ½ä¼šæ¶ˆå¤±ï¼
"""

# æ²¡æœ‰æ–‡ä»¶æ“ä½œæ—¶ï¼ˆæ•°æ®åªåœ¨å†…å­˜ä¸­ï¼‰
pcr_sequence = "ATGGAATTCGCTAGCTAG..."  # ç¨‹åºå…³é—­å°±æ¶ˆå¤±äº†ï¼

# æœ‰äº†æ–‡ä»¶æ“ä½œï¼ˆæ•°æ®æ°¸ä¹…ä¿å­˜ï¼‰
with open("tp53_pcr_product.txt", "w") as file:
    file.write(pcr_sequence)  # æ°¸ä¹…ä¿å­˜ï¼Œéšæ—¶å¯æŸ¥

print("âœ… åºåˆ—å·²ä¿å­˜ï¼æ˜å¤©ã€æ˜å¹´éƒ½è¿˜èƒ½æ‰¾åˆ°å®ƒ")
```

### çœŸå®åœºæ™¯2ï¼šæ‰¹é‡æ ·æœ¬å¤„ç†

```python
"""
åœºæ™¯ï¼šä½ æœ‰100ä¸ªç—…äººçš„åŸºå› ç»„æ•°æ®éœ€è¦åˆ†æ
æ‰‹åŠ¨å¤„ç†ï¼Ÿé‚£è¦ç´¯æ­»äº†ï¼è®©Pythonå¸®ä½ è‡ªåŠ¨åŒ–
"""

import os

# è·å–æ‰€æœ‰æ ·æœ¬æ–‡ä»¶
sample_files = [f for f in os.listdir("samples") if f.endswith(".fasta")]

# æ‰¹é‡å¤„ç†
for sample in sample_files:
    print(f"æ­£åœ¨åˆ†æ {sample}...")
    # è‡ªåŠ¨è¯»å–ã€åˆ†æã€ç”ŸæˆæŠ¥å‘Š
    # 1å°æ—¶çš„æ‰‹å·¥æ´»ï¼Œ1åˆ†é’Ÿæå®šï¼
```

### çœŸå®åœºæ™¯3ï¼šå®éªŒæ•°æ®è¿½è¸ª

```python
"""
åœºæ™¯ï¼šä¸‰ä¸ªæœˆåï¼Œå¯¼å¸ˆé—®ä½ ï¼š"å»å¹´12æœˆ15å·é‚£ä¸ªå®éªŒçš„æ•°æ®å‘¢ï¼Ÿ"
æœ‰äº†è‰¯å¥½çš„æ–‡ä»¶ç®¡ç†ï¼Œè½»æ¾æ‰¾åˆ°ï¼
"""

from datetime import datetime

# è‡ªåŠ¨å‘½åæ–‡ä»¶ï¼ŒåŒ…å«æ—¥æœŸå’Œå®éªŒä¿¡æ¯
def save_experiment_data(data, experiment_type):
    today = datetime.now().strftime("%Y%m%d")
    filename = f"{today}_{experiment_type}_results.txt"
    
    with open(filename, "w") as f:
        f.write(f"å®éªŒæ—¥æœŸï¼š{datetime.now()}\n")
        f.write(f"å®éªŒç±»å‹ï¼š{experiment_type}\n")
        f.write(f"æ•°æ®ï¼š\n{data}\n")
    
    return filename

# ä½¿ç”¨ç¤ºä¾‹
filename = save_experiment_data("ATCGATCG...", "PCR")
print(f"æ•°æ®å·²ä¿å­˜åˆ°ï¼š{filename}")
# è¾“å‡ºï¼šæ•°æ®å·²ä¿å­˜åˆ°ï¼š20240115_PCR_results.txt
```

## ğŸ—‚ï¸ ç¬¬äºŒéƒ¨åˆ†ï¼šæ–‡ä»¶ç³»ç»ŸåŸºç¡€ - ä½ çš„æ•°å­—å®éªŒå®¤

### 1. ç†è§£æ–‡ä»¶ç³»ç»Ÿå±‚çº§

```python
"""
æ–‡ä»¶ç³»ç»Ÿå°±åƒå®éªŒå®¤çš„å‚¨ç‰©æŸœï¼š
- æ ¹ç›®å½• = å®éªŒå®¤å¤§é—¨
- æ–‡ä»¶å¤¹ = ä¸åŒçš„å‚¨ç‰©æŸœ
- æ–‡ä»¶ = å‚¨ç‰©æŸœé‡Œçš„å®éªŒè®°å½•æœ¬
"""

import os

# æŸ¥çœ‹å½“å‰ä½ç½®ï¼ˆä½ åœ¨å®éªŒå®¤çš„å“ªä¸ªæˆ¿é—´ï¼Ÿï¼‰
current_dir = os.getcwd()
print(f"å½“å‰ä½ç½®ï¼š{current_dir}")

# åˆ—å‡ºå½“å‰ç›®å½•çš„å†…å®¹ï¼ˆè¿™ä¸ªæˆ¿é—´æœ‰ä»€ä¹ˆï¼Ÿï¼‰
contents = os.listdir(".")
print("\nå½“å‰ç›®å½•åŒ…å«ï¼š")
for item in contents:
    if os.path.isfile(item):
        print(f"  ğŸ“„ æ–‡ä»¶ï¼š{item}")
    elif os.path.isdir(item):
        print(f"  ğŸ“ æ–‡ä»¶å¤¹ï¼š{item}")
```

### 2. è·¯å¾„çš„æ¦‚å¿µ - å¯»æ‰¾ä½ çš„å®éªŒæ•°æ®

```python
"""
è·¯å¾„å°±åƒå®éªŒå®¤çš„åœ°å€ï¼š
- ç»å¯¹è·¯å¾„ = å®Œæ•´åœ°å€ï¼ˆä»å®éªŒæ¥¼å¤§é—¨å¼€å§‹ï¼‰
- ç›¸å¯¹è·¯å¾„ = ç›¸å¯¹ä½ç½®ï¼ˆä»å½“å‰ä½ç½®å¼€å§‹ï¼‰
"""

import os

# ç»å¯¹è·¯å¾„ï¼ˆå®Œæ•´åœ°å€ï¼‰
absolute_path = r"C:\Research\Projects\Gene_Analysis\data.fasta"
print(f"ç»å¯¹è·¯å¾„ç¤ºä¾‹ï¼š{absolute_path}")

# ç›¸å¯¹è·¯å¾„ï¼ˆç›¸å¯¹ä½ç½®ï¼‰
relative_path = "data/sequences.fasta"
print(f"ç›¸å¯¹è·¯å¾„ç¤ºä¾‹ï¼š{relative_path}")

# è·¯å¾„ç»„åˆï¼ˆæ‹¼æ¥è·¯å¾„ï¼‰
base_dir = "experiments"
filename = "pcr_results.txt"
full_path = os.path.join(base_dir, filename)
print(f"ç»„åˆè·¯å¾„ï¼š{full_path}")  # experiments/pcr_results.txt

# è·¯å¾„åˆ†è§£ï¼ˆæ‹†åˆ†è·¯å¾„ï¼‰
path = "data/2024/january/experiment.txt"
directory = os.path.dirname(path)  # data/2024/january
filename = os.path.basename(path)  # experiment.txt
print(f"ç›®å½•ï¼š{directory}")
print(f"æ–‡ä»¶åï¼š{filename}")
```

### 3. åˆ›å»ºç›®å½•ç»“æ„ - ç»„ç»‡ä½ çš„ç ”ç©¶é¡¹ç›®

```python
"""
è‰¯å¥½çš„ç›®å½•ç»“æ„å°±åƒæ•´æ´çš„å®éªŒå°ï¼Œ
è®©ä½ çš„ç ”ç©¶æ•°æ®äº•äº•æœ‰æ¡
"""

import os

def setup_project_structure(project_name):
    """
    åˆ›å»ºæ ‡å‡†çš„ç”Ÿç‰©ä¿¡æ¯å­¦é¡¹ç›®ç»“æ„
    """
    # å®šä¹‰é¡¹ç›®ç»“æ„
    structure = {
        f"{project_name}": {
            "data": {
                "raw": "åŸå§‹æµ‹åºæ•°æ®",
                "processed": "å¤„ç†åçš„æ•°æ®",
                "reference": "å‚è€ƒåŸºå› ç»„"
            },
            "results": {
                "alignments": "åºåˆ—æ¯”å¯¹ç»“æœ",
                "variants": "å˜å¼‚åˆ†æç»“æœ",
                "figures": "å›¾è¡¨è¾“å‡º"
            },
            "scripts": "åˆ†æè„šæœ¬",
            "logs": "è¿è¡Œæ—¥å¿—",
            "docs": "é¡¹ç›®æ–‡æ¡£"
        }
    }
    
    # åˆ›å»ºç›®å½•
    def create_dirs(base_path, structure_dict):
        for dir_name, sub_structure in structure_dict.items():
            dir_path = os.path.join(base_path, dir_name)
            
            # åˆ›å»ºç›®å½•
            os.makedirs(dir_path, exist_ok=True)
            print(f"âœ… åˆ›å»ºç›®å½•ï¼š{dir_path}")
            
            # é€’å½’åˆ›å»ºå­ç›®å½•
            if isinstance(sub_structure, dict):
                create_dirs(dir_path, sub_structure)
    
    create_dirs(".", structure)
    print(f"\nğŸ‰ é¡¹ç›® '{project_name}' ç»“æ„åˆ›å»ºå®Œæˆï¼")

# ä½¿ç”¨ç¤ºä¾‹
# setup_project_structure("COVID19_Analysis")
```

## ğŸ“ ç¬¬ä¸‰éƒ¨åˆ†ï¼šæ–‡ä»¶æ“ä½œè¯¦è§£ - æŒæ¡ä½ çš„æ•°å­—è®°å½•æœ¬

### 1. æ–‡ä»¶æ‰“å¼€æ¨¡å¼å®Œå…¨æŒ‡å—

```python
"""
æ–‡ä»¶æ‰“å¼€æ¨¡å¼å°±åƒä½¿ç”¨å®éªŒè®°å½•æœ¬çš„ä¸åŒæ–¹å¼ï¼š
æ¯ç§æ¨¡å¼éƒ½æœ‰ç‰¹å®šçš„ç”¨é€”
"""

# æ¨¡å¼è¯¦è§£ä¸ç¤ºä¾‹
def demonstrate_file_modes():
    print("æ–‡ä»¶æ‰“å¼€æ¨¡å¼æ¼”ç¤º")
    print("=" * 60)
    
    # æ¨¡å¼ 'r' - åªè¯»æ¨¡å¼ï¼ˆReadï¼‰
    print("\n1. 'r' æ¨¡å¼ - æŸ¥é˜…å†å²è®°å½•")
    print("   ç”¨é€”ï¼šè¯»å–ç°æœ‰æ–‡ä»¶ï¼Œä¸èƒ½ä¿®æ”¹")
    try:
        with open("existing_data.txt", "r") as f:
            content = f.read()
            print(f"   è¯»å–å†…å®¹ï¼š{content}")
    except FileNotFoundError:
        print("   æ³¨æ„ï¼šæ–‡ä»¶ä¸å­˜åœ¨æ—¶ä¼šæŠ¥é”™ï¼")
    
    # æ¨¡å¼ 'w' - å†™å…¥æ¨¡å¼ï¼ˆWriteï¼‰
    print("\n2. 'w' æ¨¡å¼ - å…¨æ–°è®°å½•")
    print("   ç”¨é€”ï¼šåˆ›å»ºæ–°æ–‡ä»¶æˆ–è¦†ç›–ç°æœ‰æ–‡ä»¶")
    with open("new_data.txt", "w") as f:
        f.write("è¿™æ˜¯å…¨æ–°çš„æ•°æ®\n")
        f.write("ä¹‹å‰çš„å†…å®¹ä¼šè¢«è¦†ç›–ï¼")
        print("   âœ… æ–°æ–‡ä»¶å·²åˆ›å»º")
    
    # æ¨¡å¼ 'a' - è¿½åŠ æ¨¡å¼ï¼ˆAppendï¼‰
    print("\n3. 'a' æ¨¡å¼ - ç»­å†™è®°å½•")
    print("   ç”¨é€”ï¼šåœ¨æ–‡ä»¶æœ«å°¾æ·»åŠ å†…å®¹")
    with open("log.txt", "a") as f:
        f.write(f"æ–°æ—¥å¿—æ¡ç›®ï¼šå®éªŒå®Œæˆ\n")
        print("   âœ… å†…å®¹å·²è¿½åŠ ")
    
    # æ¨¡å¼ 'r+' - è¯»å†™æ¨¡å¼
    print("\n4. 'r+' æ¨¡å¼ - è¾¹è¯»è¾¹æ”¹")
    print("   ç”¨é€”ï¼šè¯»å–å¹¶ä¿®æ”¹æ–‡ä»¶")
    with open("data.txt", "r+") as f:
        content = f.read()
        f.write("\nè¿½åŠ çš„å†…å®¹")
        print("   âœ… å¯ä»¥åŒæ—¶è¯»å†™")
    
    # æ¨¡å¼ 'x' - ç‹¬å åˆ›å»ºæ¨¡å¼
    print("\n5. 'x' æ¨¡å¼ - ç‹¬å åˆ›å»º")
    print("   ç”¨é€”ï¼šä»…å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶åˆ›å»º")
    try:
        with open("unique.txt", "x") as f:
            f.write("è¿™ä¸ªæ–‡ä»¶ä¹‹å‰ä¸å­˜åœ¨")
            print("   âœ… ç‹¬å æ–‡ä»¶å·²åˆ›å»º")
    except FileExistsError:
        print("   æ³¨æ„ï¼šæ–‡ä»¶å·²å­˜åœ¨ï¼Œæ— æ³•åˆ›å»ºï¼")
    
    # äºŒè¿›åˆ¶æ¨¡å¼
    print("\n6. 'b' æ ‡å¿— - äºŒè¿›åˆ¶æ¨¡å¼")
    print("   ç”¨é€”ï¼šå¤„ç†éæ–‡æœ¬æ–‡ä»¶ï¼ˆå›¾åƒã€å‹ç¼©æ–‡ä»¶ç­‰ï¼‰")
    with open("data.bin", "wb") as f:
        f.write(b'\x00\x01\x02\x03')  # å†™å…¥å­—èŠ‚
        print("   âœ… äºŒè¿›åˆ¶æ•°æ®å·²å†™å…¥")
```

### 2. è¯»å–æ–‡ä»¶çš„å¤šç§æ–¹æ³•

```python
"""
è¯»å–æ–‡ä»¶å°±åƒç¿»é˜…å®éªŒè®°å½•æœ¬ï¼Œ
æœ‰æ—¶ä½ æƒ³çœ‹å…¨éƒ¨ï¼Œæœ‰æ—¶åªæƒ³çœ‹æŸä¸€é¡µ
"""

def demonstrate_reading_methods():
    # å…ˆåˆ›å»ºä¸€ä¸ªç¤ºä¾‹æ–‡ä»¶
    sample_content = """ç¬¬ä¸€è¡Œï¼šå®éªŒæ—¥æœŸ 2024-01-15
ç¬¬äºŒè¡Œï¼šæ ·æœ¬ç¼–å· S001
ç¬¬ä¸‰è¡Œï¼šPCRç»“æœ é˜³æ€§
ç¬¬å››è¡Œï¼šæµ‹åºæ·±åº¦ 100X
ç¬¬äº”è¡Œï¼šçªå˜ä½ç‚¹ c.215C>G"""
    
    with open("sample.txt", "w", encoding="utf-8") as f:
        f.write(sample_content)
    
    print("æ–‡ä»¶è¯»å–æ–¹æ³•æ¼”ç¤º")
    print("=" * 60)
    
    # æ–¹æ³•1ï¼šread() - ä¸€æ¬¡æ€§è¯»å–å…¨éƒ¨
    print("\næ–¹æ³•1ï¼šread() - è¯»å–å…¨éƒ¨å†…å®¹")
    with open("sample.txt", "r", encoding="utf-8") as f:
        all_content = f.read()
        print("è¯»å–ç»“æœï¼š")
        print(all_content)
        print(f"æ€»å­—ç¬¦æ•°ï¼š{len(all_content)}")
    
    # æ–¹æ³•2ï¼šreadline() - é€è¡Œè¯»å–
    print("\næ–¹æ³•2ï¼šreadline() - è¯»å–ä¸€è¡Œ")
    with open("sample.txt", "r", encoding="utf-8") as f:
        first_line = f.readline()
        second_line = f.readline()
        print(f"ç¬¬ä¸€è¡Œï¼š{first_line.strip()}")
        print(f"ç¬¬äºŒè¡Œï¼š{second_line.strip()}")
    
    # æ–¹æ³•3ï¼šreadlines() - è¯»å–æ‰€æœ‰è¡Œåˆ°åˆ—è¡¨
    print("\næ–¹æ³•3ï¼šreadlines() - è¯»å–æ‰€æœ‰è¡Œåˆ°åˆ—è¡¨")
    with open("sample.txt", "r", encoding="utf-8") as f:
        all_lines = f.readlines()
        print(f"å…±{len(all_lines)}è¡Œï¼š")
        for i, line in enumerate(all_lines, 1):
            print(f"  è¡Œ{i}ï¼š{line.strip()}")
    
    # æ–¹æ³•4ï¼šè¿­ä»£å™¨æ–¹å¼ï¼ˆæ¨èï¼‰
    print("\næ–¹æ³•4ï¼šè¿­ä»£å™¨ - å†…å­˜å‹å¥½çš„é€è¡Œå¤„ç†")
    with open("sample.txt", "r", encoding="utf-8") as f:
        for line_num, line in enumerate(f, 1):
            print(f"  å¤„ç†ç¬¬{line_num}è¡Œï¼š{line.strip()}")
    
    # æ–¹æ³•5ï¼šread(size) - è¯»å–æŒ‡å®šå­—èŠ‚æ•°
    print("\næ–¹æ³•5ï¼šread(size) - åˆ†å—è¯»å–")
    with open("sample.txt", "r", encoding="utf-8") as f:
        chunk1 = f.read(20)  # è¯»å–20ä¸ªå­—ç¬¦
        chunk2 = f.read(20)  # å†è¯»20ä¸ªå­—ç¬¦
        print(f"å—1ï¼š{chunk1}")
        print(f"å—2ï¼š{chunk2}")
    
    # æ¸…ç†æ–‡ä»¶
    os.remove("sample.txt")

# è¿è¡Œæ¼”ç¤º
demonstrate_reading_methods()
```

### 3. å†™å…¥æ–‡ä»¶çš„æŠ€å·§

```python
"""
å†™å…¥æ–‡ä»¶å°±åƒåœ¨å®éªŒè®°å½•æœ¬ä¸Šè®°å½•æ•°æ®ï¼Œ
éœ€è¦æ¸…æ™°ã€æœ‰æ¡ç†ã€æ˜“äºæŸ¥æ‰¾
"""

def demonstrate_writing_techniques():
    print("æ–‡ä»¶å†™å…¥æŠ€å·§æ¼”ç¤º")
    print("=" * 60)
    
    # æŠ€å·§1ï¼šæ ¼å¼åŒ–å†™å…¥
    print("\næŠ€å·§1ï¼šæ ¼å¼åŒ–å†™å…¥ - ç”Ÿæˆå®éªŒæŠ¥å‘Š")
    
    experiment_data = {
        "date": "2024-01-15",
        "researcher": "Dr. Wang",
        "sample_id": "S001",
        "gene": "TP53",
        "mutation": "c.215C>G",
        "frequency": 0.45
    }
    
    with open("experiment_report.txt", "w", encoding="utf-8") as f:
        f.write("=" * 50 + "\n")
        f.write("å®éªŒæŠ¥å‘Š\n")
        f.write("=" * 50 + "\n\n")
        
        for key, value in experiment_data.items():
            # ä½¿ç”¨æ ¼å¼åŒ–å­—ç¬¦ä¸²
            f.write(f"{key:15s}: {value}\n")
        
        f.write("\n" + "=" * 50 + "\n")
    
    print("âœ… æ ¼å¼åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ")
    
    # æŠ€å·§2ï¼šæ‰¹é‡å†™å…¥
    print("\næŠ€å·§2ï¼šwritelines() - æ‰¹é‡å†™å…¥å¤šè¡Œ")
    
    sequences = [
        ">seq1\n",
        "ATCGATCGATCG\n",
        ">seq2\n",
        "GCTAGCTAGCTA\n"
    ]
    
    with open("sequences.fasta", "w") as f:
        f.writelines(sequences)  # ä¸€æ¬¡å†™å…¥å¤šè¡Œ
    
    print("âœ… æ‰¹é‡æ•°æ®å·²å†™å…¥")
    
    # æŠ€å·§3ï¼šä½¿ç”¨printå‡½æ•°å†™å…¥æ–‡ä»¶
    print("\næŠ€å·§3ï¼šä½¿ç”¨printå†™å…¥ - æ›´çµæ´»çš„æ–¹å¼")
    
    with open("analysis_log.txt", "w") as f:
        print("åˆ†æå¼€å§‹", file=f)
        print(f"æ—¶é—´ï¼š{datetime.now()}", file=f)
        print("å‚æ•°è®¾ç½®ï¼š", file=f)
        print("  - æœ€å°è´¨é‡å€¼ï¼š30", file=f)
        print("  - æœ€å°è¦†ç›–åº¦ï¼š10X", file=f)
        print("åˆ†æå®Œæˆ", file=f)
    
    print("âœ… æ—¥å¿—æ–‡ä»¶å·²åˆ›å»º")
    
    # æŠ€å·§4ï¼šå®‰å…¨å†™å…¥ï¼ˆå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼‰
    print("\næŠ€å·§4ï¼šå®‰å…¨å†™å…¥ - é˜²æ­¢æ•°æ®ä¸¢å¤±")
    
    import shutil
    
    def safe_write(filename, content):
        """å®‰å…¨å†™å…¥ï¼šå…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼ŒæˆåŠŸåæ›¿æ¢"""
        temp_file = filename + ".tmp"
        
        try:
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶
            with open(temp_file, "w") as f:
                f.write(content)
            
            # æˆåŠŸåæ›¿æ¢åŸæ–‡ä»¶
            shutil.move(temp_file, filename)
            return True
            
        except Exception as e:
            # å‡ºé”™æ—¶åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_file):
                os.remove(temp_file)
            print(f"å†™å…¥å¤±è´¥ï¼š{e}")
            return False
    
    # ä½¿ç”¨å®‰å…¨å†™å…¥
    important_data = "è¿™æ˜¯é‡è¦æ•°æ®ï¼Œä¸èƒ½ä¸¢å¤±ï¼"
    if safe_write("important.txt", important_data):
        print("âœ… é‡è¦æ•°æ®å·²å®‰å…¨ä¿å­˜")
```

### 4. æ–‡ä»¶ä½ç½®æ§åˆ¶

```python
"""
æ–‡ä»¶æŒ‡é’ˆå°±åƒä½ çš„æ‰‹æŒ‡åœ¨ä¹¦é¡µä¸Šçš„ä½ç½®ï¼Œ
å¯ä»¥ç²¾ç¡®æ§åˆ¶ä»å“ªé‡Œå¼€å§‹è¯»å†™
"""

def demonstrate_file_position():
    print("æ–‡ä»¶ä½ç½®æ§åˆ¶æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºç¤ºä¾‹æ–‡ä»¶
    with open("position_demo.txt", "w") as f:
        f.write("0123456789ABCDEFGHIJ")
    
    with open("position_demo.txt", "r+") as f:
        # tell() - è·å–å½“å‰ä½ç½®
        print(f"\nåˆå§‹ä½ç½®ï¼š{f.tell()}")  # 0
        
        # è¯»å–5ä¸ªå­—ç¬¦
        data = f.read(5)
        print(f"è¯»å– '{data}'")
        print(f"å½“å‰ä½ç½®ï¼š{f.tell()}")  # 5
        
        # seek() - ç§»åŠ¨åˆ°æŒ‡å®šä½ç½®
        f.seek(10)  # ç§»åŠ¨åˆ°ç¬¬10ä¸ªå­—ç¬¦
        print(f"\nç§»åŠ¨åˆ°ä½ç½®10")
        data = f.read(5)
        print(f"è¯»å– '{data}'")  # ABCDE
        
        # seek()çš„ä¸åŒç”¨æ³•
        f.seek(0)  # å›åˆ°æ–‡ä»¶å¼€å¤´
        print(f"\nå›åˆ°å¼€å¤´ï¼Œä½ç½®ï¼š{f.tell()}")
        
        f.seek(0, 2)  # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
        print(f"ç§»åŠ¨åˆ°æœ«å°¾ï¼Œä½ç½®ï¼š{f.tell()}")
        
        # åœ¨ç‰¹å®šä½ç½®å†™å…¥
        f.seek(5)
        f.write("***")  # è¦†ç›–ä½ç½®5-7çš„å†…å®¹
        
        # æŸ¥çœ‹ä¿®æ”¹åçš„å†…å®¹
        f.seek(0)
        final_content = f.read()
        print(f"\nä¿®æ”¹åçš„å†…å®¹ï¼š{final_content}")
    
    # æ¸…ç†
    os.remove("position_demo.txt")
```

## ğŸ§¬ ç¬¬å››éƒ¨åˆ†ï¼šæ–‡æœ¬ç¼–ç  - ç†è§£å­—ç¬¦çš„æ•°å­—å¯†ç 

### 1. ç¼–ç åŸºç¡€æ¦‚å¿µ

```python
"""
ç¼–ç å°±åƒæŠŠæ–‡å­—ç¿»è¯‘æˆè®¡ç®—æœºèƒ½ç†è§£çš„æ•°å­—ï¼š
- ASCIIï¼šæœ€æ—©çš„ç¼–ç ï¼Œåªèƒ½è¡¨ç¤ºè‹±æ–‡
- UTF-8ï¼šä¸‡å›½ç ï¼Œå¯ä»¥è¡¨ç¤ºå…¨ä¸–ç•Œçš„æ–‡å­—
- GBKï¼šä¸­æ–‡ç¼–ç 

åœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨UTF-8
"""

def demonstrate_encoding():
    print("æ–‡æœ¬ç¼–ç æ¼”ç¤º")
    print("=" * 60)
    
    # æ¼”ç¤ºä¸åŒç¼–ç 
    text = "DNAåºåˆ—ï¼šATCG"
    
    # UTF-8ç¼–ç ï¼ˆæ¨èï¼‰
    print("\n1. UTF-8ç¼–ç ï¼ˆæ¨èï¼‰")
    with open("utf8.txt", "w", encoding="utf-8") as f:
        f.write(text)
    print("âœ… UTF-8æ–‡ä»¶å·²åˆ›å»º")
    
    # è¯»å–æ—¶æŒ‡å®šç¼–ç 
    with open("utf8.txt", "r", encoding="utf-8") as f:
        content = f.read()
        print(f"è¯»å–å†…å®¹ï¼š{content}")
    
    # å¤„ç†ç¼–ç é”™è¯¯
    print("\n2. å¤„ç†ç¼–ç é”™è¯¯")
    
    # åˆ›å»ºä¸€ä¸ªåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ–‡ä»¶
    special_text = "åŸºå› ï¼šÎ²-globin, ä½ç½®ï¼š11p15.5"
    with open("special.txt", "w", encoding="utf-8") as f:
        f.write(special_text)
    
    # é”™è¯¯çš„ç¼–ç æ–¹å¼
    try:
        with open("special.txt", "r", encoding="ascii") as f:
            content = f.read()
    except UnicodeDecodeError as e:
        print(f"âŒ ASCIIæ— æ³•è¯»å–ï¼š{e}")
    
    # æ­£ç¡®çš„ç¼–ç æ–¹å¼
    with open("special.txt", "r", encoding="utf-8") as f:
        content = f.read()
        print(f"âœ… UTF-8æ­£ç¡®è¯»å–ï¼š{content}")
    
    # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
    print("\n3. è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ")
    
    def detect_encoding(filename):
        """ç®€å•çš„ç¼–ç æ£€æµ‹"""
        encodings = ['utf-8', 'gbk', 'latin-1', 'ascii']
        
        for encoding in encodings:
            try:
                with open(filename, 'r', encoding=encoding) as f:
                    f.read()
                return encoding
            except UnicodeDecodeError:
                continue
        
        return None
    
    detected = detect_encoding("special.txt")
    print(f"æ£€æµ‹åˆ°çš„ç¼–ç ï¼š{detected}")
    
    # æ¸…ç†æ–‡ä»¶
    for f in ["utf8.txt", "special.txt"]:
        if os.path.exists(f):
            os.remove(f)
```

### 2. å¤„ç†ä¸åŒæ¥æºçš„æ–‡ä»¶

```python
"""
ä¸åŒæ“ä½œç³»ç»Ÿå’Œè½¯ä»¶å¯èƒ½ä½¿ç”¨ä¸åŒçš„ç¼–ç å’Œæ¢è¡Œç¬¦
Windows: \r\n
Linux/Mac: \n
"""

def handle_cross_platform_files():
    print("è·¨å¹³å°æ–‡ä»¶å¤„ç†")
    print("=" * 60)
    
    # å¤„ç†ä¸åŒçš„æ¢è¡Œç¬¦
    print("\n1. å¤„ç†ä¸åŒæ¢è¡Œç¬¦")
    
    # Windowsæ ¼å¼
    with open("windows.txt", "w", newline='\r\n') as f:
        f.write("ç¬¬ä¸€è¡Œ\r\nç¬¬äºŒè¡Œ\r\n")
    
    # Unixæ ¼å¼
    with open("unix.txt", "w", newline='\n') as f:
        f.write("ç¬¬ä¸€è¡Œ\nç¬¬äºŒè¡Œ\n")
    
    # Pythonè‡ªåŠ¨å¤„ç†ï¼ˆæ¨èï¼‰
    with open("windows.txt", "r") as f:
        lines = f.readlines()
        print("Windowsæ–‡ä»¶çš„è¡Œï¼š")
        for line in lines:
            print(f"  '{line.strip()}'")  # strip()å»é™¤æ¢è¡Œç¬¦
    
    # ç»Ÿä¸€æ¢è¡Œç¬¦
    print("\n2. ç»Ÿä¸€æ¢è¡Œç¬¦æ ¼å¼")
    
    def normalize_line_endings(input_file, output_file):
        """å°†æ–‡ä»¶è½¬æ¢ä¸ºç»Ÿä¸€çš„æ¢è¡Œç¬¦æ ¼å¼"""
        with open(input_file, "r") as f_in:
            content = f_in.read()
        
        # ç»Ÿä¸€ä¸º\n
        content = content.replace('\r\n', '\n').replace('\r', '\n')
        
        with open(output_file, "w", newline='\n') as f_out:
            f_out.write(content)
        
        print(f"âœ… å·²ç»Ÿä¸€æ¢è¡Œç¬¦ï¼š{output_file}")
    
    # æ¸…ç†æ–‡ä»¶
    for f in ["windows.txt", "unix.txt"]:
        if os.path.exists(f):
            os.remove(f)
```

## ğŸ§¬ ç¬¬äº”éƒ¨åˆ†ï¼šFASTAæ ¼å¼æ·±å…¥å‰–æ

### 1. FASTAæ ¼å¼çš„å†å²ä¸æ¼”å˜

```python
"""
FASTAæ ¼å¼çš„æ•…äº‹ï¼š
1985å¹´ï¼ŒWilliam Pearsonå¼€å‘äº†FASTAç®—æ³•
éšä¹‹è¯ç”Ÿçš„FASTAæ–‡ä»¶æ ¼å¼æˆä¸ºäº†ç”Ÿç‰©ä¿¡æ¯å­¦çš„æ ‡å‡†

ä¸ºä»€ä¹ˆFASTAå¦‚æ­¤æˆåŠŸï¼Ÿ
1. ç®€å• - ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨éƒ½èƒ½æ‰“å¼€
2. çµæ´» - å¯ä»¥å­˜å‚¨å„ç§åºåˆ—ä¿¡æ¯
3. é€šç”¨ - å‡ ä¹æ‰€æœ‰ç”Ÿç‰©ä¿¡æ¯å­¦è½¯ä»¶éƒ½æ”¯æŒ
"""

def explore_fasta_format():
    print("FASTAæ ¼å¼æ·±åº¦è§£æ")
    print("=" * 60)
    
    # FASTAæ ¼å¼è§„èŒƒ
    print("\n1. æ ‡å‡†FASTAæ ¼å¼")
    
    standard_fasta = """>gi|123456|ref|NM_001234.5| Homo sapiens gene (GENE), mRNA
ATGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCG
GCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCG
GCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCGGCG
>gi|789012|ref|NP_567890.1| protein name [Homo sapiens]
MTEYKLVVVGAGGVGKSALTIQLIQNHFVDEYDPTIEDSYRKQVVIDGETCLLDILDTAG
QEEYSAMRDQYMRTGEGFLCVFAINNTKSFEDIHQYREQIKRVKDSDDVPMVLVGNKCDL
"""
    
    print("æ ‡å‡†FASTAç¤ºä¾‹ï¼š")
    print(standard_fasta)
    
    # è§£ææ ‡é¢˜è¡Œ
    print("\n2. æ ‡é¢˜è¡Œæ ¼å¼è§£æ")
    
    def parse_fasta_header(header):
        """è§£æFASTAæ ‡é¢˜è¡Œçš„ä¸åŒæ ¼å¼"""
        # å»é™¤å¼€å¤´çš„>
        header = header.lstrip('>')
        
        # NCBIæ ¼å¼
        if '|' in header:
            parts = header.split('|')
            return {
                'format': 'NCBI',
                'database': parts[0] if len(parts) > 0 else '',
                'id': parts[1] if len(parts) > 1 else '',
                'accession': parts[3] if len(parts) > 3 else '',
                'description': parts[4] if len(parts) > 4 else ''
            }
        
        # ç®€å•æ ¼å¼
        else:
            parts = header.split(None, 1)
            return {
                'format': 'Simple',
                'id': parts[0] if parts else '',
                'description': parts[1] if len(parts) > 1 else ''
            }
    
    headers = [
        ">gi|123456|ref|NM_001234.5| Homo sapiens gene",
        ">ENSG00000141510 TP53 tumor protein p53",
        ">seq1",
        ">chr1:1000-2000 forward strand"
    ]
    
    for header in headers:
        parsed = parse_fasta_header(header)
        print(f"\nåŸå§‹ï¼š{header}")
        print(f"è§£æï¼š{parsed}")
    
    # FASTAå˜ä½“
    print("\n3. FASTAæ ¼å¼å˜ä½“")
    
    # å¤šè¡Œåºåˆ—
    print("\n3a. å¤šè¡Œåºåˆ—ï¼ˆæ ‡å‡†ï¼‰")
    multiline_fasta = """>sequence_1
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
TTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCC
"""
    print(multiline_fasta)
    
    # å•è¡Œåºåˆ—
    print("3b. å•è¡Œåºåˆ—ï¼ˆç®€åŒ–ï¼‰")
    singleline_fasta = """>sequence_1
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTATTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCC
"""
    print(singleline_fasta)
    
    # å¸¦è´¨é‡å€¼çš„FASTQï¼ˆç›¸å…³æ ¼å¼ï¼‰
    print("\n3c. FASTQæ ¼å¼ï¼ˆFASTAçš„è¡¨äº²ï¼‰")
    fastq_example = """@sequence_1
ATCGATCGATCGATCGATCGATCG
+
IIIIIIIIHHHHHHHHHHHHHHHH
"""
    print(fastq_example)
```

### 2. FASTAæ–‡ä»¶çš„è´¨é‡æ ‡å‡†

```python
"""
ä»€ä¹ˆæ˜¯é«˜è´¨é‡çš„FASTAæ–‡ä»¶ï¼Ÿ
å°±åƒå®éªŒè®°å½•è¦è§„èŒƒä¸€æ ·ï¼ŒFASTAæ–‡ä»¶ä¹Ÿæœ‰æ ‡å‡†
"""

def check_fasta_quality():
    print("FASTAæ–‡ä»¶è´¨é‡æ£€æŸ¥")
    print("=" * 60)
    
    def validate_fasta(filename):
        """
        å…¨é¢æ£€æŸ¥FASTAæ–‡ä»¶è´¨é‡
        è¿”å›è´¨é‡æŠ¥å‘Š
        """
        report = {
            'total_sequences': 0,
            'total_length': 0,
            'issues': [],
            'warnings': [],
            'stats': {}
        }
        
        valid_dna = set('ATCGN')
        valid_protein = set('ACDEFGHIKLMNPQRSTVWY*')
        
        with open(filename, 'r') as f:
            current_id = None
            current_seq = []
            line_num = 0
            
            for line in f:
                line_num += 1
                line = line.strip()
                
                # ç©ºè¡Œ
                if not line:
                    continue
                
                # æ ‡é¢˜è¡Œ
                if line.startswith('>'):
                    # å¤„ç†å‰ä¸€æ¡åºåˆ—
                    if current_id:
                        sequence = ''.join(current_seq).upper()
                        report['total_sequences'] += 1
                        report['total_length'] += len(sequence)
                        
                        # æ£€æŸ¥åºåˆ—å†…å®¹
                        invalid_chars = set(sequence) - valid_dna - valid_protein
                        if invalid_chars:
                            report['warnings'].append(
                                f"åºåˆ— {current_id} åŒ…å«éæ ‡å‡†å­—ç¬¦: {invalid_chars}"
                            )
                        
                        # æ£€æŸ¥åºåˆ—é•¿åº¦
                        if len(sequence) == 0:
                            report['issues'].append(
                                f"åºåˆ— {current_id} ä¸ºç©º"
                            )
                        elif len(sequence) < 10:
                            report['warnings'].append(
                                f"åºåˆ— {current_id} å¤ªçŸ­ ({len(sequence)} bp)"
                            )
                    
                    # æ£€æŸ¥æ ‡é¢˜æ ¼å¼
                    if len(line) == 1:  # åªæœ‰>
                        report['issues'].append(
                            f"è¡Œ {line_num}: ç©ºæ ‡é¢˜"
                        )
                        current_id = f"unnamed_{line_num}"
                    else:
                        current_id = line[1:].split()[0]
                    
                    current_seq = []
                
                # åºåˆ—è¡Œ
                else:
                    if current_id is None:
                        report['issues'].append(
                            f"è¡Œ {line_num}: åºåˆ—å‡ºç°åœ¨æ ‡é¢˜ä¹‹å‰"
                        )
                    else:
                        current_seq.append(line)
            
            # å¤„ç†æœ€åä¸€æ¡åºåˆ—
            if current_id:
                sequence = ''.join(current_seq).upper()
                report['total_sequences'] += 1
                report['total_length'] += len(sequence)
        
        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        if report['total_sequences'] > 0:
            report['stats'] = {
                'average_length': report['total_length'] / report['total_sequences'],
                'quality_score': 100 - len(report['issues']) * 10 - len(report['warnings']) * 2
            }
        
        return report
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    test_files = {
        "good.fasta": """>seq1 good sequence
ATCGATCGATCGATCGATCGATCG
>seq2 another good one
GCTAGCTAGCTAGCTAGCTAGCTA
""",
        "bad.fasta": """>
ATCG
>seq2
123ATCG456
>seq3
"""
    }
    
    for filename, content in test_files.items():
        with open(filename, 'w') as f:
            f.write(content)
        
        print(f"\næ£€æŸ¥æ–‡ä»¶ï¼š{filename}")
        report = validate_fasta(filename)
        
        print(f"åºåˆ—æ•°ï¼š{report['total_sequences']}")
        print(f"æ€»é•¿åº¦ï¼š{report['total_length']}")
        
        if report['issues']:
            print("âŒ ä¸¥é‡é—®é¢˜ï¼š")
            for issue in report['issues']:
                print(f"  - {issue}")
        
        if report['warnings']:
            print("âš ï¸ è­¦å‘Šï¼š")
            for warning in report['warnings']:
                print(f"  - {warning}")
        
        if report['stats']:
            print(f"è´¨é‡åˆ†æ•°ï¼š{report['stats']['quality_score']}/100")
        
        # æ¸…ç†
        os.remove(filename)
```

## ğŸ”§ ç¬¬å…­éƒ¨åˆ†ï¼šæ„å»ºä¸“ä¸šçš„FASTAè§£æå™¨

### 1. ç‰ˆæœ¬1ï¼šå…¥é—¨çº§è§£æå™¨

```python
"""
ç¬¬ä¸€æ­¥ï¼šèƒ½ç”¨å°±è¡Œ
å°±åƒç¬¬ä¸€æ¬¡åšPCRï¼Œå…ˆè®©å®ƒè·‘èµ·æ¥ï¼
"""

def build_parser_v1():
    print("æ„å»ºFASTAè§£æå™¨ - ç‰ˆæœ¬1ï¼šå…¥é—¨çº§")
    print("=" * 60)
    
    def parse_fasta_basic(filename):
        """
        æœ€ç®€å•çš„FASTAè§£æå™¨
        ä¼˜ç‚¹ï¼šä»£ç ç®€å•ï¼Œæ˜“äºç†è§£
        ç¼ºç‚¹ï¼šå†…å­˜å ç”¨å¤§ï¼ŒåŠŸèƒ½æœ‰é™
        """
        sequences = {}
        
        with open(filename, 'r') as f:
            content = f.read()
        
        # æŒ‰>åˆ†å‰²è·å–æ¯æ¡åºåˆ—
        entries = content.split('>')[1:]  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºå…ƒç´ 
        
        for entry in entries:
            lines = entry.strip().split('\n')
            if lines:
                header = lines[0]
                sequence = ''.join(lines[1:])
                seq_id = header.split()[0]
                sequences[seq_id] = sequence
        
        return sequences
    
    # æµ‹è¯•
    test_fasta = """>gene1
ATCGATCG
GCTAGCTA
>gene2
TTTTAAAA
CCCCGGGG
"""
    
    with open("test_v1.fasta", "w") as f:
        f.write(test_fasta)
    
    result = parse_fasta_basic("test_v1.fasta")
    print("\nè§£æç»“æœï¼š")
    for seq_id, sequence in result.items():
        print(f"  {seq_id}: {sequence}")
    
    print("\nâœ… ä¼˜ç‚¹ï¼šç®€å•ç›´è§‚")
    print("âŒ ç¼ºç‚¹ï¼šå¤§æ–‡ä»¶ä¼šå ç”¨å¤§é‡å†…å­˜")
    
    os.remove("test_v1.fasta")
```

### 2. ç‰ˆæœ¬2ï¼šå®ç”¨çº§è§£æå™¨

```python
"""
ç¬¬äºŒæ­¥ï¼šæ›´ä¸“ä¸šä¸€ç‚¹
åƒç†Ÿç»ƒçš„å®éªŒå‘˜ï¼ŒçŸ¥é“å„ç§æŠ€å·§
"""

def build_parser_v2():
    print("\næ„å»ºFASTAè§£æå™¨ - ç‰ˆæœ¬2ï¼šå®ç”¨çº§")
    print("=" * 60)
    
    class FastaParser:
        """
        å®ç”¨çš„FASTAè§£æå™¨ç±»
        æ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼å’ŒåŸºæœ¬ç»Ÿè®¡
        """
        
        def __init__(self, filename):
            self.filename = filename
            self.sequences = []
            self._parse()
        
        def _parse(self):
            """è§£æFASTAæ–‡ä»¶"""
            current_id = None
            current_desc = ""
            current_seq = []
            
            with open(self.filename, 'r') as f:
                for line in f:
                    line = line.strip()
                    
                    if not line:
                        continue
                    
                    if line.startswith('>'):
                        # ä¿å­˜å‰ä¸€æ¡åºåˆ—
                        if current_id:
                            self.sequences.append({
                                'id': current_id,
                                'description': current_desc,
                                'sequence': ''.join(current_seq).upper()
                            })
                        
                        # è§£ææ–°æ ‡é¢˜
                        header_parts = line[1:].split(None, 1)
                        current_id = header_parts[0]
                        current_desc = header_parts[1] if len(header_parts) > 1 else ""
                        current_seq = []
                    else:
                        current_seq.append(line)
                
                # ä¿å­˜æœ€åä¸€æ¡
                if current_id:
                    self.sequences.append({
                        'id': current_id,
                        'description': current_desc,
                        'sequence': ''.join(current_seq).upper()
                    })
        
        def get_sequence(self, seq_id):
            """è·å–æŒ‡å®šIDçš„åºåˆ—"""
            for seq in self.sequences:
                if seq['id'] == seq_id:
                    return seq['sequence']
            return None
        
        def get_ids(self):
            """è·å–æ‰€æœ‰åºåˆ—ID"""
            return [seq['id'] for seq in self.sequences]
        
        def statistics(self):
            """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
            stats = {
                'count': len(self.sequences),
                'total_length': sum(len(seq['sequence']) for seq in self.sequences),
                'lengths': [len(seq['sequence']) for seq in self.sequences]
            }
            
            if stats['count'] > 0:
                stats['average_length'] = stats['total_length'] / stats['count']
                stats['min_length'] = min(stats['lengths'])
                stats['max_length'] = max(stats['lengths'])
            
            return stats
        
        def to_dict(self):
            """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
            return {seq['id']: seq['sequence'] for seq in self.sequences}
        
        def filter_by_length(self, min_length=0, max_length=float('inf')):
            """æŒ‰é•¿åº¦è¿‡æ»¤åºåˆ—"""
            filtered = []
            for seq in self.sequences:
                length = len(seq['sequence'])
                if min_length <= length <= max_length:
                    filtered.append(seq)
            return filtered
    
    # æµ‹è¯•
    test_fasta = """>gene1 important gene
ATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTA
>gene2 another gene
TTTTAAAACCCCGGGG
>gene3 long gene
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
TTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCCGGGG
"""
    
    with open("test_v2.fasta", "w") as f:
        f.write(test_fasta)
    
    # ä½¿ç”¨è§£æå™¨
    parser = FastaParser("test_v2.fasta")
    
    print("\nè§£æç»“æœï¼š")
    print(f"åºåˆ—æ•°ï¼š{len(parser.sequences)}")
    print(f"åºåˆ—IDï¼š{parser.get_ids()}")
    
    print("\nç»Ÿè®¡ä¿¡æ¯ï¼š")
    stats = parser.statistics()
    for key, value in stats.items():
        if key != 'lengths':
            print(f"  {key}: {value}")
    
    print("\né•¿åº¦è¿‡æ»¤ï¼ˆ>30bpï¼‰ï¼š")
    filtered = parser.filter_by_length(min_length=30)
    for seq in filtered:
        print(f"  {seq['id']}: {len(seq['sequence'])} bp")
    
    os.remove("test_v2.fasta")
```

### 3. ç‰ˆæœ¬3ï¼šä¸“ä¸šçº§è§£æå™¨ï¼ˆç”Ÿæˆå™¨ç‰ˆæœ¬ï¼‰

```python
"""
ç¬¬ä¸‰æ­¥ï¼šä¸“ä¸šæ°´å‡†
åƒç»éªŒä¸°å¯Œçš„ç”Ÿç‰©ä¿¡æ¯å­¦å®¶ï¼Œä¼˜é›…è€Œé«˜æ•ˆ
"""

def build_parser_v3():
    print("\næ„å»ºFASTAè§£æå™¨ - ç‰ˆæœ¬3ï¼šä¸“ä¸šçº§")
    print("=" * 60)
    
    class ProfessionalFastaParser:
        """
        ä¸“ä¸šçº§FASTAè§£æå™¨
        - ä½¿ç”¨ç”Ÿæˆå™¨ï¼Œå†…å­˜æ•ˆç‡é«˜
        - å®Œæ•´çš„é”™è¯¯å¤„ç†
        - æ”¯æŒå¤§æ–‡ä»¶
        - å¯æ‰©å±•çš„æ¶æ„
        """
        
        def __init__(self, filename, validate=True):
            self.filename = filename
            self.validate = validate
            self._file_handle = None
            self._check_file()
        
        def _check_file(self):
            """æ£€æŸ¥æ–‡ä»¶æœ‰æ•ˆæ€§"""
            if not os.path.exists(self.filename):
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{self.filename}")
            
            if os.path.getsize(self.filename) == 0:
                raise ValueError("æ–‡ä»¶ä¸ºç©º")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯FASTAæ ¼å¼
            with open(self.filename, 'r') as f:
                first_line = f.readline().strip()
                if not first_line.startswith('>'):
                    raise ValueError("ä¸æ˜¯æœ‰æ•ˆçš„FASTAæ–‡ä»¶")
        
        def parse(self):
            """
            ç”Ÿæˆå™¨æ–¹å¼è§£æFASTA
            é€æ¡yieldåºåˆ—ï¼Œä¸å ç”¨å†…å­˜
            """
            current_record = None
            
            with open(self.filename, 'r') as f:
                for line_num, line in enumerate(f, 1):
                    line = line.strip()
                    
                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Š
                    if not line or line.startswith('#'):
                        continue
                    
                    if line.startswith('>'):
                        # è¾“å‡ºå‰ä¸€æ¡è®°å½•
                        if current_record and current_record['sequence']:
                            if self.validate:
                                self._validate_sequence(current_record)
                            yield current_record
                        
                        # å¼€å§‹æ–°è®°å½•
                        current_record = self._parse_header(line, line_num)
                    else:
                        # ç´¯ç§¯åºåˆ—
                        if current_record:
                            current_record['sequence'] += line.upper()
                        else:
                            raise ValueError(f"è¡Œ {line_num}: åºåˆ—å‡ºç°åœ¨æ ‡é¢˜ä¹‹å‰")
                
                # è¾“å‡ºæœ€åä¸€æ¡
                if current_record and current_record['sequence']:
                    if self.validate:
                        self._validate_sequence(current_record)
                    yield current_record
        
        def _parse_header(self, line, line_num):
            """è§£ææ ‡é¢˜è¡Œ"""
            header = line[1:].strip()
            
            if not header:
                header = f"unnamed_seq_{line_num}"
            
            parts = header.split(None, 1)
            
            return {
                'id': parts[0],
                'description': parts[1] if len(parts) > 1 else '',
                'sequence': '',
                'line_number': line_num
            }
        
        def _validate_sequence(self, record):
            """éªŒè¯åºåˆ—æœ‰æ•ˆæ€§"""
            sequence = record['sequence']
            
            # DNA/RNAç¢±åŸº
            valid_nucleotides = set('ATCGUN')
            # è›‹ç™½è´¨æ°¨åŸºé…¸
            valid_amino_acids = set('ACDEFGHIKLMNPQRSTVWY*')
            
            # åˆ¤æ–­åºåˆ—ç±»å‹
            seq_chars = set(sequence)
            
            if seq_chars <= valid_nucleotides:
                record['type'] = 'nucleotide'
                record['gc_content'] = self._calculate_gc(sequence)
            elif seq_chars <= valid_amino_acids:
                record['type'] = 'protein'
            else:
                invalid = seq_chars - valid_nucleotides - valid_amino_acids
                record['warnings'] = f"åŒ…å«éæ ‡å‡†å­—ç¬¦: {invalid}"
        
        def _calculate_gc(self, sequence):
            """è®¡ç®—GCå«é‡"""
            gc_count = sequence.count('G') + sequence.count('C')
            total = len(sequence)
            return (gc_count / total * 100) if total > 0 else 0
        
        def iterate_chunks(self, chunk_size=1000000):
            """
            æŒ‰å—è¿­ä»£åºåˆ—ï¼ˆç”¨äºè¶…å¤§åºåˆ—ï¼‰
            """
            for record in self.parse():
                sequence = record['sequence']
                record_info = {
                    'id': record['id'],
                    'description': record['description']
                }
                
                for i in range(0, len(sequence), chunk_size):
                    chunk = sequence[i:i + chunk_size]
                    yield {
                        **record_info,
                        'chunk_index': i // chunk_size,
                        'chunk': chunk
                    }
        
        def search(self, pattern, search_in='id'):
            """
            æœç´¢åºåˆ—
            search_in: 'id', 'description', 'sequence'
            """
            import re
            
            pattern_re = re.compile(pattern, re.IGNORECASE)
            
            for record in self.parse():
                if search_in == 'id' and pattern_re.search(record['id']):
                    yield record
                elif search_in == 'description' and pattern_re.search(record['description']):
                    yield record
                elif search_in == 'sequence' and pattern_re.search(record['sequence']):
                    yield record
        
        def extract_subset(self, id_list, output_file):
            """æå–æŒ‡å®šIDçš„åºåˆ—å­é›†"""
            id_set = set(id_list)
            found = set()
            
            with open(output_file, 'w') as out:
                for record in self.parse():
                    if record['id'] in id_set:
                        out.write(f">{record['id']} {record['description']}\n")
                        # æ¯60ä¸ªå­—ç¬¦æ¢è¡Œ
                        seq = record['sequence']
                        for i in range(0, len(seq), 60):
                            out.write(seq[i:i+60] + '\n')
                        found.add(record['id'])
            
            not_found = id_set - found
            if not_found:
                print(f"è­¦å‘Šï¼šæœªæ‰¾åˆ°ä»¥ä¸‹ID: {not_found}")
            
            return len(found)
    
    # æµ‹è¯•ä¸“ä¸šè§£æå™¨
    test_fasta = """>NM_001 p53 tumor suppressor
ATGGAGGAGCCGCAGTCAGATCCTAGCGTCGAGCCCCCTCTGAGTCAGGAAACATTTTC
AGACCTATGGAAACTACTTCCTGAAAACAACGTTCTGTCCCCCTTGCCGTCCCAAGCAA
>NM_002 BRCA1 breast cancer gene  
ATGGATTTATCTGCTCTTCGCGTTGAAGAAGTACAAAATGTCATTAATGCTATGCAGAA
AATCTTAGAGTGTCCCATCTGTCTGGAGTTGATCAAGGAACCTGTCTCCACAAAGTGTG
>NP_003 myoglobin protein
MGLSDGEWQLVLNVWGKVEADIPGHGQEVLIRLFKGHPETLEKFDKFKHLKSEDEMKASED
"""
    
    with open("test_v3.fasta", "w") as f:
        f.write(test_fasta)
    
    # ä½¿ç”¨ä¸“ä¸šè§£æå™¨
    parser = ProfessionalFastaParser("test_v3.fasta")
    
    print("\nä½¿ç”¨ç”Ÿæˆå™¨è§£æï¼ˆå†…å­˜å‹å¥½ï¼‰ï¼š")
    for record in parser.parse():
        print(f"\nID: {record['id']}")
        print(f"æè¿°: {record['description']}")
        print(f"ç±»å‹: {record.get('type', 'unknown')}")
        print(f"é•¿åº¦: {len(record['sequence'])} bp")
        if 'gc_content' in record:
            print(f"GCå«é‡: {record['gc_content']:.1f}%")
    
    print("\næœç´¢åŠŸèƒ½æ¼”ç¤ºï¼š")
    print("æœç´¢æè¿°ä¸­åŒ…å«'cancer'çš„åºåˆ—ï¼š")
    for record in parser.search('cancer', search_in='description'):
        print(f"  æ‰¾åˆ°: {record['id']} - {record['description']}")
    
    os.remove("test_v3.fasta")
```

## ğŸ’¾ ç¬¬ä¸ƒéƒ¨åˆ†ï¼šå¤§æ–‡ä»¶å¤„ç†ç­–ç•¥

### 1. å†…å­˜ç®¡ç†åŸºç¡€

```python
"""
å¤„ç†å¤§æ–‡ä»¶å°±åƒæ¬è¿è´§ç‰©ï¼š
- ä¸€æ¬¡æ€§æ¬è¿ï¼ˆread()ï¼‰ï¼šç´¯æ­»äººï¼Œå¯èƒ½æ¬ä¸åŠ¨
- åˆ†æ‰¹æ¬è¿ï¼ˆç”Ÿæˆå™¨ï¼‰ï¼šè½»æ¾é«˜æ•ˆ
"""

def demonstrate_memory_management():
    print("å¤§æ–‡ä»¶å†…å­˜ç®¡ç†ç­–ç•¥")
    print("=" * 60)
    
    import sys
    
    # åˆ›å»ºæµ‹è¯•æ–‡ä»¶
    def create_large_file(filename, size_mb):
        """åˆ›å»ºæŒ‡å®šå¤§å°çš„æµ‹è¯•æ–‡ä»¶"""
        import random
        
        size_bytes = size_mb * 1024 * 1024
        chunk_size = 1024  # 1KB chunks
        
        with open(filename, 'w') as f:
            written = 0
            seq_num = 1
            
            while written < size_bytes:
                # å†™å…¥FASTAæ ¼å¼
                f.write(f">sequence_{seq_num}\n")
                # ç”Ÿæˆéšæœºåºåˆ—
                seq = ''.join(random.choices('ATCG', k=min(1000, size_bytes - written)))
                f.write(seq + '\n')
                
                written += len(f">sequence_{seq_num}\n") + len(seq) + 1
                seq_num += 1
        
        return seq_num - 1
    
    # æ–¹æ³•1ï¼šä¸æ¨è - ä¸€æ¬¡æ€§è¯»å–
    def process_all_at_once(filename):
        """å†…å­˜å¯†é›†å‹å¤„ç†"""
        with open(filename, 'r') as f:
            content = f.read()  # å…¨éƒ¨åŠ è½½åˆ°å†…å­˜ï¼
            
        # è·å–å†…å­˜ä½¿ç”¨
        size = sys.getsizeof(content)
        return size, content.count('>')
    
    # æ–¹æ³•2ï¼šæ¨è - é€è¡Œå¤„ç†
    def process_line_by_line(filename):
        """å†…å­˜å‹å¥½å‹å¤„ç†"""
        count = 0
        max_line_size = 0
        
        with open(filename, 'r') as f:
            for line in f:
                if line.startswith('>'):
                    count += 1
                max_line_size = max(max_line_size, sys.getsizeof(line))
        
        return max_line_size, count
    
    # æ–¹æ³•3ï¼šæœ€ä¼˜ - ç”Ÿæˆå™¨å¤„ç†
    def process_with_generator(filename):
        """ä½¿ç”¨ç”Ÿæˆå™¨çš„ä¸“ä¸šå¤„ç†"""
        def sequence_generator():
            with open(filename, 'r') as f:
                current_seq = None
                for line in f:
                    if line.startswith('>'):
                        if current_seq:
                            yield current_seq
                        current_seq = {'header': line.strip(), 'sequence': ''}
                    elif current_seq:
                        current_seq['sequence'] += line.strip()
                
                if current_seq:
                    yield current_seq
        
        count = 0
        total_length = 0
        
        for seq in sequence_generator():
            count += 1
            total_length += len(seq['sequence'])
        
        return count, total_length
    
    # æµ‹è¯•
    print("\nåˆ›å»ºæµ‹è¯•æ–‡ä»¶ï¼ˆ1MBï¼‰...")
    num_seqs = create_large_file("test_large.fasta", 1)
    print(f"âœ… åˆ›å»ºäº†åŒ…å« {num_seqs} æ¡åºåˆ—çš„æ–‡ä»¶")
    
    # æ¯”è¾ƒå†…å­˜ä½¿ç”¨
    print("\nå†…å­˜ä½¿ç”¨æ¯”è¾ƒï¼š")
    
    print("\n1. ä¸€æ¬¡æ€§è¯»å–ï¼š")
    memory, count = process_all_at_once("test_large.fasta")
    print(f"   å†…å­˜å ç”¨ï¼š{memory / 1024:.1f} KB")
    print(f"   åºåˆ—æ•°ï¼š{count}")
    
    print("\n2. é€è¡Œè¯»å–ï¼š")
    max_line_memory, count = process_line_by_line("test_large.fasta")
    print(f"   æœ€å¤§è¡Œå†…å­˜ï¼š{max_line_memory / 1024:.1f} KB")
    print(f"   åºåˆ—æ•°ï¼š{count}")
    
    print("\n3. ç”Ÿæˆå™¨å¤„ç†ï¼š")
    count, total_length = process_with_generator("test_large.fasta")
    print(f"   åºåˆ—æ•°ï¼š{count}")
    print(f"   æ€»é•¿åº¦ï¼š{total_length} bp")
    print(f"   å†…å­˜å ç”¨ï¼šæå°ï¼ˆåªå­˜å‚¨å½“å‰åºåˆ—ï¼‰")
    
    # æ¸…ç†
    os.remove("test_large.fasta")
```

### 2. æµå¼å¤„ç†Pipeline

```python
"""
æµå¼å¤„ç†å°±åƒç”Ÿäº§çº¿ï¼š
æ•°æ®åƒæµæ°´ä¸€æ ·ç»è¿‡å„ä¸ªå¤„ç†æ­¥éª¤ï¼Œ
ä¸éœ€è¦ç­‰å¾…å…¨éƒ¨å®Œæˆ
"""

def build_streaming_pipeline():
    print("\næµå¼å¤„ç†Pipeline")
    print("=" * 60)
    
    class SequencePipeline:
        """
        åºåˆ—å¤„ç†æµæ°´çº¿
        æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨ï¼Œå†…å­˜æ•ˆç‡æé«˜
        """
        
        @staticmethod
        def read_fasta(filename):
            """æ­¥éª¤1ï¼šè¯»å–FASTAæ–‡ä»¶"""
            with open(filename, 'r') as f:
                header = None
                sequence = []
                
                for line in f:
                    line = line.strip()
                    if line.startswith('>'):
                        if header:
                            yield {
                                'header': header,
                                'sequence': ''.join(sequence)
                            }
                        header = line[1:]
                        sequence = []
                    else:
                        sequence.append(line)
                
                if header:
                    yield {
                        'header': header,
                        'sequence': ''.join(sequence)
                    }
        
        @staticmethod
        def filter_length(sequences, min_length=100):
            """æ­¥éª¤2ï¼šè¿‡æ»¤çŸ­åºåˆ—"""
            for seq in sequences:
                if len(seq['sequence']) >= min_length:
                    yield seq
        
        @staticmethod
        def calculate_gc(sequences):
            """æ­¥éª¤3ï¼šè®¡ç®—GCå«é‡"""
            for seq in sequences:
                sequence = seq['sequence'].upper()
                gc = sequence.count('G') + sequence.count('C')
                length = len(sequence)
                seq['gc_content'] = (gc / length * 100) if length > 0 else 0
                yield seq
        
        @staticmethod
        def filter_gc(sequences, min_gc=40, max_gc=60):
            """æ­¥éª¤4ï¼šæŒ‰GCå«é‡è¿‡æ»¤"""
            for seq in sequences:
                if min_gc <= seq['gc_content'] <= max_gc:
                    yield seq
        
        @staticmethod
        def format_output(sequences):
            """æ­¥éª¤5ï¼šæ ¼å¼åŒ–è¾“å‡º"""
            for i, seq in enumerate(sequences, 1):
                yield {
                    'index': i,
                    'id': seq['header'].split()[0],
                    'length': len(seq['sequence']),
                    'gc': f"{seq['gc_content']:.1f}%",
                    'sequence': seq['sequence'][:50] + '...' if len(seq['sequence']) > 50 else seq['sequence']
                }
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_data = """>seq1 short sequence
ATCG
>seq2 medium sequence
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
>seq3 high GC sequence
GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC
GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC
CGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCG
>seq4 normal sequence
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
TTTTAAAACCCCGGGGTTTTAAAACCCCGGGGTTTTAAAACCCCGGGG
"""
    
    with open("pipeline_test.fasta", "w") as f:
        f.write(test_data)
    
    # æ„å»ºPipeline
    print("\næ„å»ºå¤„ç†æµæ°´çº¿ï¼š")
    print("  1. è¯»å–FASTA")
    print("  2. è¿‡æ»¤é•¿åº¦ >= 100bp")
    print("  3. è®¡ç®—GCå«é‡")
    print("  4. è¿‡æ»¤GCå«é‡ 40-60%")
    print("  5. æ ¼å¼åŒ–è¾“å‡º")
    
    # æ‰§è¡ŒPipeline
    pipeline = SequencePipeline()
    
    # é“¾å¼è°ƒç”¨ç”Ÿæˆå™¨
    sequences = pipeline.read_fasta("pipeline_test.fasta")
    sequences = pipeline.filter_length(sequences, min_length=100)
    sequences = pipeline.calculate_gc(sequences)
    sequences = pipeline.filter_gc(sequences, min_gc=40, max_gc=60)
    sequences = pipeline.format_output(sequences)
    
    # è¾“å‡ºç»“æœ
    print("\nå¤„ç†ç»“æœï¼š")
    for result in sequences:
        print(f"\nåºåˆ— {result['index']}:")
        print(f"  ID: {result['id']}")
        print(f"  é•¿åº¦: {result['length']} bp")
        print(f"  GCå«é‡: {result['gc']}")
        print(f"  åºåˆ—é¢„è§ˆ: {result['sequence']}")
    
    # æ¸…ç†
    os.remove("pipeline_test.fasta")
```

### 3. å¹¶è¡Œå¤„ç†ç­–ç•¥

```python
"""
å¹¶è¡Œå¤„ç†å°±åƒå¤šä¸ªå®éªŒå‘˜åŒæ—¶å·¥ä½œï¼š
æŠŠå¤§ä»»åŠ¡åˆ†ç»™å¤šä¸ªå¤„ç†å™¨ï¼Œå¤§å¤§æé«˜æ•ˆç‡
"""

def demonstrate_parallel_processing():
    print("\nå¹¶è¡Œå¤„ç†ç­–ç•¥")
    print("=" * 60)
    
    from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
    import time
    
    def process_sequence(seq_data):
        """å¤„ç†å•æ¡åºåˆ—ï¼ˆæ¨¡æ‹Ÿè€—æ—¶æ“ä½œï¼‰"""
        seq_id, sequence = seq_data
        
        # æ¨¡æ‹Ÿå¤æ‚è®¡ç®—
        gc_content = (sequence.count('G') + sequence.count('C')) / len(sequence) * 100
        
        # æŸ¥æ‰¾æ¨¡å¼
        patterns_found = []
        if 'ATCG' in sequence:
            patterns_found.append('ATCG')
        if 'GGGG' in sequence:
            patterns_found.append('GGGG')
        
        return {
            'id': seq_id,
            'length': len(sequence),
            'gc_content': gc_content,
            'patterns': patterns_found
        }
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_sequences = []
    for i in range(100):
        import random
        seq_id = f"seq_{i:03d}"
        sequence = ''.join(random.choices('ATCG', k=1000))
        test_sequences.append((seq_id, sequence))
    
    print(f"å‡†å¤‡å¤„ç† {len(test_sequences)} æ¡åºåˆ—")
    
    # ä¸²è¡Œå¤„ç†
    print("\n1. ä¸²è¡Œå¤„ç†ï¼š")
    start_time = time.time()
    
    serial_results = []
    for seq_data in test_sequences:
        result = process_sequence(seq_data)
        serial_results.append(result)
    
    serial_time = time.time() - start_time
    print(f"   è€—æ—¶ï¼š{serial_time:.3f} ç§’")
    
    # çº¿ç¨‹å¹¶è¡Œï¼ˆé€‚åˆI/Oå¯†é›†å‹ï¼‰
    print("\n2. çº¿ç¨‹å¹¶è¡Œå¤„ç†ï¼š")
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        thread_results = list(executor.map(process_sequence, test_sequences))
    
    thread_time = time.time() - start_time
    print(f"   è€—æ—¶ï¼š{thread_time:.3f} ç§’")
    print(f"   åŠ é€Ÿæ¯”ï¼š{serial_time/thread_time:.2f}x")
    
    # è¿›ç¨‹å¹¶è¡Œï¼ˆé€‚åˆCPUå¯†é›†å‹ï¼‰
    print("\n3. è¿›ç¨‹å¹¶è¡Œå¤„ç†ï¼š")
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        process_results = list(executor.map(process_sequence, test_sequences))
    
    process_time = time.time() - start_time
    print(f"   è€—æ—¶ï¼š{process_time:.3f} ç§’")
    print(f"   åŠ é€Ÿæ¯”ï¼š{serial_time/process_time:.2f}x")
    
    # æ‰¹å¤„ç†ç­–ç•¥
    print("\n4. æ‰¹å¤„ç†ç­–ç•¥ï¼š")
    
    def process_batch(batch):
        """å¤„ç†ä¸€æ‰¹åºåˆ—"""
        results = []
        for seq_data in batch:
            results.append(process_sequence(seq_data))
        return results
    
    # å°†åºåˆ—åˆ†æ‰¹
    batch_size = 25
    batches = [test_sequences[i:i+batch_size] 
               for i in range(0, len(test_sequences), batch_size)]
    
    start_time = time.time()
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        batch_results = executor.map(process_batch, batches)
        
    # å±•å¹³ç»“æœ
    final_results = []
    for batch_result in batch_results:
        final_results.extend(batch_result)
    
    batch_time = time.time() - start_time
    print(f"   æ‰¹å¤§å°ï¼š{batch_size}")
    print(f"   æ‰¹æ•°é‡ï¼š{len(batches)}")
    print(f"   è€—æ—¶ï¼š{batch_time:.3f} ç§’")
    print(f"   åŠ é€Ÿæ¯”ï¼š{serial_time/batch_time:.2f}x")
```

## âš ï¸ ç¬¬å…«éƒ¨åˆ†ï¼šé”™è¯¯å¤„ç†çš„è‰ºæœ¯

### 1. å¸¸è§é”™è¯¯ç±»å‹ä¸å¤„ç†

```python
"""
é”™è¯¯å¤„ç†å°±åƒå®éªŒå®¤çš„å®‰å…¨è§„ç¨‹ï¼š
é¢„é˜²ä¸ºä¸»ï¼Œå¤„ç†ä¸ºè¾…
"""

def demonstrate_error_handling():
    print("é”™è¯¯å¤„ç†å®Œå…¨æŒ‡å—")
    print("=" * 60)
    
    # 1. æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯
    print("\n1. å¤„ç†æ–‡ä»¶ä¸å­˜åœ¨é”™è¯¯ï¼š")
    
    def safe_read_file(filename):
        """å®‰å…¨è¯»å–æ–‡ä»¶ï¼Œå¸¦é”™è¯¯å¤„ç†"""
        try:
            with open(filename, 'r') as f:
                return f.read()
        except FileNotFoundError:
            print(f"âŒ é”™è¯¯ï¼šæ–‡ä»¶ '{filename}' ä¸å­˜åœ¨")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            print("   1. æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦æ­£ç¡®")
            print("   2. æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®")
            print("   3. ç¡®è®¤æ–‡ä»¶ç¡®å®å­˜åœ¨")
            
            # æä¾›æ›¿ä»£æ–¹æ¡ˆ
            response = input("æ˜¯å¦åˆ›å»ºæ–°æ–‡ä»¶ï¼Ÿ(y/n): ")
            if response.lower() == 'y':
                with open(filename, 'w') as f:
                    f.write("# æ–°å»ºæ–‡ä»¶\n")
                print(f"âœ… å·²åˆ›å»ºæ–‡ä»¶ï¼š{filename}")
                return "# æ–°å»ºæ–‡ä»¶\n"
            return None
    
    # æµ‹è¯•
    content = safe_read_file("ä¸å­˜åœ¨çš„æ–‡ä»¶.txt")
    
    # 2. ç¼–ç é”™è¯¯
    print("\n2. å¤„ç†ç¼–ç é”™è¯¯ï¼š")
    
    def read_with_encoding_detection(filename):
        """è‡ªåŠ¨æ£€æµ‹å¹¶å¤„ç†ç¼–ç """
        encodings = ['utf-8', 'gbk', 'latin-1', 'cp1252']
        
        for encoding in encodings:
            try:
                with open(filename, 'r', encoding=encoding) as f:
                    content = f.read()
                print(f"âœ… æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç è¯»å–")
                return content
            except UnicodeDecodeError:
                continue
        
        # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥
        print("âŒ æ— æ³•ç¡®å®šæ–‡ä»¶ç¼–ç ")
        print("ğŸ’¡ å°è¯•äºŒè¿›åˆ¶æ¨¡å¼è¯»å–...")
        
        with open(filename, 'rb') as f:
            raw_bytes = f.read()
            print(f"è¯»å–äº† {len(raw_bytes)} å­—èŠ‚çš„äºŒè¿›åˆ¶æ•°æ®")
            return raw_bytes
    
    # 3. æƒé™é”™è¯¯
    print("\n3. å¤„ç†æƒé™é”™è¯¯ï¼š")
    
    def write_with_permission_check(filename, content):
        """æ£€æŸ¥æƒé™å¹¶å†™å…¥æ–‡ä»¶"""
        try:
            with open(filename, 'w') as f:
                f.write(content)
            print(f"âœ… æˆåŠŸå†™å…¥ï¼š{filename}")
            
        except PermissionError:
            print(f"âŒ é”™è¯¯ï¼šæ²¡æœ‰å†™å…¥æƒé™ - {filename}")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼š")
            print("   1. æ£€æŸ¥æ–‡ä»¶æ˜¯å¦è¢«å…¶ä»–ç¨‹åºå ç”¨")
            print("   2. æ£€æŸ¥æ–‡ä»¶å¤¹æƒé™è®¾ç½®")
            print("   3. å°è¯•ä½¿ç”¨ç®¡ç†å‘˜æƒé™è¿è¡Œ")
            
            # å°è¯•å†™å…¥ä¸´æ—¶æ–‡ä»¶
            import tempfile
            temp_file = tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.txt')
            temp_file.write(content)
            temp_file.close()
            print(f"âœ… å·²å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼š{temp_file.name}")
            return temp_file.name
            
        return filename
    
    # 4. å†…å­˜é”™è¯¯
    print("\n4. å¤„ç†å†…å­˜é”™è¯¯ï¼š")
    
    def process_large_file_safely(filename):
        """å®‰å…¨å¤„ç†å¤§æ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(filename)
            
            if file_size > 100 * 1024 * 1024:  # 100MB
                print(f"âš ï¸ è­¦å‘Šï¼šæ–‡ä»¶è¾ƒå¤§ ({file_size / 1024 / 1024:.1f} MB)")
                print("ä½¿ç”¨æµå¼å¤„ç†é¿å…å†…å­˜æº¢å‡º...")
                
                # æµå¼å¤„ç†
                line_count = 0
                with open(filename, 'r') as f:
                    for line in f:
                        line_count += 1
                        # å¤„ç†æ¯ä¸€è¡Œ
                        if line_count % 10000 == 0:
                            print(f"  å·²å¤„ç† {line_count} è¡Œ...")
                
                return line_count
            else:
                # å°æ–‡ä»¶ç›´æ¥è¯»å–
                with open(filename, 'r') as f:
                    content = f.read()
                return len(content.splitlines())
                
        except MemoryError:
            print("âŒ å†…å­˜é”™è¯¯ï¼šæ–‡ä»¶å¤ªå¤§ï¼Œå†…å­˜ä¸è¶³")
            print("ğŸ’¡ è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ç”Ÿæˆå™¨æˆ–åˆ†å—å¤„ç†")
            return None
    
    # 5. æ ¼å¼é”™è¯¯
    print("\n5. å¤„ç†æ ¼å¼é”™è¯¯ï¼š")
    
    def parse_fasta_with_validation(filename):
        """å¸¦æ ¼å¼éªŒè¯çš„FASTAè§£æ"""
        errors = []
        warnings = []
        sequences = []
        
        try:
            with open(filename, 'r') as f:
                current_id = None
                current_seq = []
                line_num = 0
                
                for line in f:
                    line_num += 1
                    line = line.strip()
                    
                    if not line:
                        continue
                    
                    if line.startswith('>'):
                        # ä¿å­˜å‰ä¸€æ¡åºåˆ—
                        if current_id:
                            seq = ''.join(current_seq)
                            if not seq:
                                warnings.append(f"è¡Œ {line_num}: åºåˆ— {current_id} ä¸ºç©º")
                            else:
                                sequences.append((current_id, seq))
                        
                        # æ–°åºåˆ—
                        if len(line) == 1:
                            errors.append(f"è¡Œ {line_num}: æ ‡é¢˜è¡Œä¸ºç©º")
                            current_id = f"unnamed_{line_num}"
                        else:
                            current_id = line[1:].split()[0]
                        current_seq = []
                        
                    else:
                        if current_id is None:
                            errors.append(f"è¡Œ {line_num}: åºåˆ—å‡ºç°åœ¨æ ‡é¢˜ä¹‹å‰")
                        else:
                            # éªŒè¯åºåˆ—å­—ç¬¦
                            valid_chars = set('ATCGUN')
                            invalid = set(line.upper()) - valid_chars
                            if invalid:
                                warnings.append(f"è¡Œ {line_num}: åŒ…å«éæ ‡å‡†å­—ç¬¦ {invalid}")
                            current_seq.append(line)
                
                # ä¿å­˜æœ€åä¸€æ¡
                if current_id:
                    seq = ''.join(current_seq)
                    if seq:
                        sequences.append((current_id, seq))
            
            # æŠ¥å‘Šç»“æœ
            print(f"\nè§£æå®Œæˆï¼š")
            print(f"  âœ… æˆåŠŸè§£æ {len(sequences)} æ¡åºåˆ—")
            
            if errors:
                print(f"  âŒ å‘ç° {len(errors)} ä¸ªé”™è¯¯ï¼š")
                for error in errors[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"     - {error}")
            
            if warnings:
                print(f"  âš ï¸ å‘ç° {len(warnings)} ä¸ªè­¦å‘Šï¼š")
                for warning in warnings[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    print(f"     - {warning}")
            
            return sequences
            
        except Exception as e:
            print(f"âŒ è§£æå¤±è´¥ï¼š{e}")
            return []
```

### 2. è‡ªå®šä¹‰é”™è¯¯ç±»

```python
"""
è‡ªå®šä¹‰é”™è¯¯ç±»å°±åƒç‰¹å®šçš„å®éªŒå¼‚å¸¸ï¼š
è®©é”™è¯¯ä¿¡æ¯æ›´å‡†ç¡®ã€æ›´æœ‰å¸®åŠ©
"""

class FastaError(Exception):
    """FASTAç›¸å…³é”™è¯¯çš„åŸºç±»"""
    pass

class FastaFormatError(FastaError):
    """FASTAæ ¼å¼é”™è¯¯"""
    def __init__(self, message, line_number=None):
        self.line_number = line_number
        if line_number:
            message = f"è¡Œ {line_number}: {message}"
        super().__init__(message)

class SequenceError(FastaError):
    """åºåˆ—å†…å®¹é”™è¯¯"""
    def __init__(self, seq_id, message):
        self.seq_id = seq_id
        super().__init__(f"åºåˆ— {seq_id}: {message}")

class FastaIOError(FastaError):
    """æ–‡ä»¶IOé”™è¯¯"""
    pass

def use_custom_errors():
    print("\nè‡ªå®šä¹‰é”™è¯¯ç±»æ¼”ç¤º")
    print("=" * 60)
    
    def strict_fasta_parser(filename):
        """ä¸¥æ ¼çš„FASTAè§£æå™¨ï¼Œä½¿ç”¨è‡ªå®šä¹‰é”™è¯¯"""
        
        if not os.path.exists(filename):
            raise FastaIOError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{filename}")
        
        with open(filename, 'r') as f:
            line_num = 0
            current_id = None
            
            for line in f:
                line_num += 1
                line = line.strip()
                
                if not line:
                    continue
                
                if line.startswith('>'):
                    if len(line) == 1:
                        raise FastaFormatError("æ ‡é¢˜è¡Œä¸èƒ½ä¸ºç©º", line_num)
                    
                    current_id = line[1:].split()[0]
                    
                    if not current_id:
                        raise FastaFormatError("æ— æ³•è§£æåºåˆ—ID", line_num)
                    
                else:
                    if current_id is None:
                        raise FastaFormatError("åºåˆ—å‡ºç°åœ¨æ ‡é¢˜ä¹‹å‰", line_num)
                    
                    # æ£€æŸ¥åºåˆ—å†…å®¹
                    invalid = set(line.upper()) - set('ATCGUN')
                    if invalid:
                        raise SequenceError(current_id, f"åŒ…å«æ— æ•ˆå­—ç¬¦ï¼š{invalid}")
    
    # æµ‹è¯•è‡ªå®šä¹‰é”™è¯¯
    test_cases = [
        ("", "ç©ºæ ‡é¢˜"),
        (">", "åªæœ‰>"),
        ("ATCG\n>seq1", "åºåˆ—åœ¨æ ‡é¢˜å‰"),
        (">seq1\nAT#CG", "æ— æ•ˆå­—ç¬¦")
    ]
    
    for content, description in test_cases:
        print(f"\næµ‹è¯•ï¼š{description}")
        
        with open("error_test.fasta", "w") as f:
            f.write(content)
        
        try:
            strict_fasta_parser("error_test.fasta")
            print("âœ… é€šè¿‡éªŒè¯")
        except FastaFormatError as e:
            print(f"âŒ æ ¼å¼é”™è¯¯ï¼š{e}")
        except SequenceError as e:
            print(f"âŒ åºåˆ—é”™è¯¯ï¼š{e}")
        except FastaIOError as e:
            print(f"âŒ IOé”™è¯¯ï¼š{e}")
        finally:
            if os.path.exists("error_test.fasta"):
                os.remove("error_test.fasta")
```

## ğŸ¯ ç¬¬ä¹éƒ¨åˆ†ï¼šç»¼åˆé¡¹ç›® - æ„å»ºå®Œæ•´çš„åºåˆ—åˆ†ææµç¨‹

### é¡¹ç›®ï¼šåŸºå› ç»„åºåˆ—åˆ†æç³»ç»Ÿ

```python
"""
ç»¼åˆé¡¹ç›®ï¼šæ„å»ºä¸€ä¸ªå®Œæ•´çš„åŸºå› ç»„åºåˆ—åˆ†æç³»ç»Ÿ
åŒ…å«ï¼šæ–‡ä»¶ç®¡ç†ã€åºåˆ—åˆ†æã€è´¨é‡æ§åˆ¶ã€æŠ¥å‘Šç”Ÿæˆ
"""

class GenomeAnalysisSystem:
    """
    åŸºå› ç»„åˆ†æç³»ç»Ÿ
    ä¸€ä¸ªå®Œæ•´çš„ã€ç”Ÿäº§çº§åˆ«çš„åºåˆ—åˆ†æå·¥å…·
    """
    
    def __init__(self, project_name):
        self.project_name = project_name
        self.project_dir = f"analysis_{project_name}"
        self.statistics = {}
        self._setup_project()
    
    def _setup_project(self):
        """è®¾ç½®é¡¹ç›®ç›®å½•ç»“æ„"""
        import os
        
        # åˆ›å»ºé¡¹ç›®ç›®å½•
        dirs = [
            self.project_dir,
            f"{self.project_dir}/data",
            f"{self.project_dir}/results",
            f"{self.project_dir}/logs",
            f"{self.project_dir}/reports"
        ]
        
        for dir_path in dirs:
            os.makedirs(dir_path, exist_ok=True)
        
        print(f"âœ… é¡¹ç›® '{self.project_name}' åˆå§‹åŒ–å®Œæˆ")
        print(f"   é¡¹ç›®ç›®å½•ï¼š{self.project_dir}")
    
    def import_sequences(self, fasta_file):
        """å¯¼å…¥åºåˆ—æ–‡ä»¶"""
        import shutil
        
        if not os.path.exists(fasta_file):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼š{fasta_file}")
        
        # å¤åˆ¶åˆ°é¡¹ç›®ç›®å½•
        dest = f"{self.project_dir}/data/input.fasta"
        shutil.copy(fasta_file, dest)
        
        # éªŒè¯æ–‡ä»¶
        self._validate_fasta(dest)
        
        print(f"âœ… åºåˆ—æ–‡ä»¶å·²å¯¼å…¥ï¼š{dest}")
        return dest
    
    def _validate_fasta(self, filename):
        """éªŒè¯FASTAæ–‡ä»¶æ ¼å¼"""
        seq_count = 0
        total_length = 0
        
        with open(filename, 'r') as f:
            for line in f:
                if line.startswith('>'):
                    seq_count += 1
                else:
                    total_length += len(line.strip())
        
        if seq_count == 0:
            raise ValueError("æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°åºåˆ—")
        
        self.statistics['input_sequences'] = seq_count
        self.statistics['input_total_length'] = total_length
        
        print(f"   éªŒè¯é€šè¿‡ï¼š{seq_count} æ¡åºåˆ—ï¼Œæ€»é•¿åº¦ {total_length} bp")
    
    def quality_control(self, min_length=100, max_n_percent=5):
        """è´¨é‡æ§åˆ¶ï¼šè¿‡æ»¤ä½è´¨é‡åºåˆ—"""
        input_file = f"{self.project_dir}/data/input.fasta"
        output_file = f"{self.project_dir}/data/filtered.fasta"
        
        kept = 0
        filtered = 0
        
        with open(output_file, 'w') as out_f:
            current_header = None
            current_seq = []
            
            with open(input_file, 'r') as in_f:
                for line in in_f:
                    line = line.strip()
                    
                    if line.startswith('>'):
                        # å¤„ç†å‰ä¸€æ¡åºåˆ—
                        if current_header:
                            seq = ''.join(current_seq).upper()
                            
                            # è´¨é‡æ£€æŸ¥
                            if (len(seq) >= min_length and 
                                seq.count('N') <= len(seq) * max_n_percent / 100):
                                out_f.write(f">{current_header}\n")
                                out_f.write(f"{seq}\n")
                                kept += 1
                            else:
                                filtered += 1
                        
                        current_header = line[1:]
                        current_seq = []
                    else:
                        current_seq.append(line)
                
                # æœ€åä¸€æ¡
                if current_header:
                    seq = ''.join(current_seq).upper()
                    if (len(seq) >= min_length and 
                        seq.count('N') <= len(seq) * max_n_percent / 100):
                        out_f.write(f">{current_header}\n")
                        out_f.write(f"{seq}\n")
                        kept += 1
                    else:
                        filtered += 1
        
        self.statistics['kept_sequences'] = kept
        self.statistics['filtered_sequences'] = filtered
        
        print(f"âœ… è´¨é‡æ§åˆ¶å®Œæˆ")
        print(f"   ä¿ç•™ï¼š{kept} æ¡åºåˆ—")
        print(f"   è¿‡æ»¤ï¼š{filtered} æ¡åºåˆ—")
        
        return output_file
    
    def analyze_sequences(self):
        """åˆ†æåºåˆ—ç‰¹å¾"""
        input_file = f"{self.project_dir}/data/filtered.fasta"
        
        results = {
            'sequences': [],
            'total_length': 0,
            'gc_content_overall': 0,
            'length_distribution': []
        }
        
        total_gc = 0
        total_bases = 0
        
        with open(input_file, 'r') as f:
            current_id = None
            current_seq = []
            
            for line in f:
                line = line.strip()
                
                if line.startswith('>'):
                    if current_id:
                        seq = ''.join(current_seq).upper()
                        length = len(seq)
                        gc = seq.count('G') + seq.count('C')
                        gc_percent = (gc / length * 100) if length > 0 else 0
                        
                        results['sequences'].append({
                            'id': current_id,
                            'length': length,
                            'gc_content': gc_percent
                        })
                        
                        results['length_distribution'].append(length)
                        total_gc += gc
                        total_bases += length
                    
                    current_id = line[1:].split()[0]
                    current_seq = []
                else:
                    current_seq.append(line)
            
            # æœ€åä¸€æ¡
            if current_id:
                seq = ''.join(current_seq).upper()
                length = len(seq)
                gc = seq.count('G') + seq.count('C')
                gc_percent = (gc / length * 100) if length > 0 else 0
                
                results['sequences'].append({
                    'id': current_id,
                    'length': length,
                    'gc_content': gc_percent
                })
                
                results['length_distribution'].append(length)
                total_gc += gc
                total_bases += length
        
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        results['total_length'] = total_bases
        results['gc_content_overall'] = (total_gc / total_bases * 100) if total_bases > 0 else 0
        
        self.statistics['analysis_results'] = results
        
        print(f"âœ… åºåˆ—åˆ†æå®Œæˆ")
        print(f"   æ€»é•¿åº¦ï¼š{total_bases:,} bp")
        print(f"   æ•´ä½“GCå«é‡ï¼š{results['gc_content_overall']:.1f}%")
        
        return results
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        from datetime import datetime
        
        report_file = f"{self.project_dir}/reports/analysis_report.txt"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            # æŠ¥å‘Šå¤´
            f.write("=" * 60 + "\n")
            f.write("åŸºå› ç»„åºåˆ—åˆ†ææŠ¥å‘Š\n")
            f.write("=" * 60 + "\n\n")
            
            f.write(f"é¡¹ç›®åç§°ï¼š{self.project_name}\n")
            f.write(f"åˆ†ææ—¥æœŸï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write("\n")
            
            # è¾“å…¥æ•°æ®ç»Ÿè®¡
            f.write("è¾“å…¥æ•°æ®ç»Ÿè®¡\n")
            f.write("-" * 40 + "\n")
            f.write(f"åŸå§‹åºåˆ—æ•°ï¼š{self.statistics.get('input_sequences', 0)}\n")
            f.write(f"åŸå§‹æ€»é•¿åº¦ï¼š{self.statistics.get('input_total_length', 0):,} bp\n")
            f.write("\n")
            
            # è´¨é‡æ§åˆ¶ç»“æœ
            f.write("è´¨é‡æ§åˆ¶ç»“æœ\n")
            f.write("-" * 40 + "\n")
            f.write(f"ä¿ç•™åºåˆ—æ•°ï¼š{self.statistics.get('kept_sequences', 0)}\n")
            f.write(f"è¿‡æ»¤åºåˆ—æ•°ï¼š{self.statistics.get('filtered_sequences', 0)}\n")
            filter_rate = (self.statistics.get('filtered_sequences', 0) / 
                          self.statistics.get('input_sequences', 1) * 100)
            f.write(f"è¿‡æ»¤ç‡ï¼š{filter_rate:.1f}%\n")
            f.write("\n")
            
            # åºåˆ—åˆ†æç»“æœ
            if 'analysis_results' in self.statistics:
                results = self.statistics['analysis_results']
                
                f.write("åºåˆ—ç‰¹å¾åˆ†æ\n")
                f.write("-" * 40 + "\n")
                f.write(f"åˆ†æåºåˆ—æ•°ï¼š{len(results['sequences'])}\n")
                f.write(f"æ€»é•¿åº¦ï¼š{results['total_length']:,} bp\n")
                f.write(f"å¹³å‡é•¿åº¦ï¼š{results['total_length'] / len(results['sequences']):.1f} bp\n")
                f.write(f"æœ€çŸ­åºåˆ—ï¼š{min(results['length_distribution'])} bp\n")
                f.write(f"æœ€é•¿åºåˆ—ï¼š{max(results['length_distribution'])} bp\n")
                f.write(f"æ•´ä½“GCå«é‡ï¼š{results['gc_content_overall']:.2f}%\n")
                f.write("\n")
                
                # è¯¦ç»†åºåˆ—åˆ—è¡¨
                f.write("åºåˆ—è¯¦æƒ…ï¼ˆå‰10æ¡ï¼‰\n")
                f.write("-" * 40 + "\n")
                f.write(f"{'åºåˆ—ID':<20} {'é•¿åº¦(bp)':<10} {'GCå«é‡(%)':<10}\n")
                f.write("-" * 40 + "\n")
                
                for seq in results['sequences'][:10]:
                    f.write(f"{seq['id']:<20} {seq['length']:<10} {seq['gc_content']:<10.1f}\n")
                
                if len(results['sequences']) > 10:
                    f.write(f"... è¿˜æœ‰ {len(results['sequences']) - 10} æ¡åºåˆ—\n")
            
            f.write("\n" + "=" * 60 + "\n")
            f.write("æŠ¥å‘Šç»“æŸ\n")
        
        print(f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{report_file}")
        
        # åŒæ—¶ç”ŸæˆCSVæ ¼å¼
        csv_file = f"{self.project_dir}/reports/sequences.csv"
        with open(csv_file, 'w') as f:
            f.write("ID,Length,GC_Content\n")
            if 'analysis_results' in self.statistics:
                for seq in self.statistics['analysis_results']['sequences']:
                    f.write(f"{seq['id']},{seq['length']},{seq['gc_content']:.2f}\n")
        
        print(f"âœ… CSVæ•°æ®å·²ç”Ÿæˆï¼š{csv_file}")
        
        return report_file

# ä½¿ç”¨ç¤ºä¾‹
def run_analysis_project():
    print("ğŸ§¬ è¿è¡ŒåŸºå› ç»„åˆ†æé¡¹ç›®")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_fasta = """>chr1_gene1
ATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCGATCG
GCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTAGCTA
>chr1_gene2_short
ATCG
>chr1_gene3_with_N
ATCGATCGATCNNNNNGATCGATCGATCGATCGATCGATCGATCGATCG
>chr2_gene1
GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC
GCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGCGC
>chr2_gene2
ATATATATATATATATATATATATATATATATATATATATATATATAT
ATATATATATATATATATATATATATATATATATATATATATATATAT
"""
    
    with open("test_genome.fasta", "w") as f:
        f.write(test_fasta)
    
    # åˆ›å»ºåˆ†æç³»ç»Ÿ
    system = GenomeAnalysisSystem("COVID19_Variants")
    
    try:
        # æ­¥éª¤1ï¼šå¯¼å…¥æ•°æ®
        print("\næ­¥éª¤1ï¼šå¯¼å…¥åºåˆ—æ•°æ®")
        system.import_sequences("test_genome.fasta")
        
        # æ­¥éª¤2ï¼šè´¨é‡æ§åˆ¶
        print("\næ­¥éª¤2ï¼šè´¨é‡æ§åˆ¶")
        system.quality_control(min_length=50, max_n_percent=5)
        
        # æ­¥éª¤3ï¼šåºåˆ—åˆ†æ
        print("\næ­¥éª¤3ï¼šåºåˆ—åˆ†æ")
        system.analyze_sequences()
        
        # æ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Š
        print("\næ­¥éª¤4ï¼šç”ŸæˆæŠ¥å‘Š")
        report = system.generate_report()
        
        # æ˜¾ç¤ºæŠ¥å‘Šå†…å®¹
        print("\n" + "=" * 60)
        print("æŠ¥å‘Šé¢„è§ˆï¼š")
        with open(report, 'r') as f:
            lines = f.readlines()[:20]  # æ˜¾ç¤ºå‰20è¡Œ
            for line in lines:
                print(line.rstrip())
        print("...")
        
    finally:
        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if os.path.exists("test_genome.fasta"):
            os.remove("test_genome.fasta")
        
        # å¯é€‰ï¼šæ¸…ç†é¡¹ç›®ç›®å½•
        # import shutil
        # if os.path.exists(system.project_dir):
        #     shutil.rmtree(system.project_dir)

# è¿è¡Œé¡¹ç›®
# run_analysis_project()
```

## ğŸ’ª ç»ƒä¹ é¢˜é¢„è§ˆ

æœ¬ç« é…å¥—äº†ä¸°å¯Œçš„ç»ƒä¹ é¢˜ï¼Œä»ç®€å•åˆ°å¤æ‚ï¼Œå¸®åŠ©ä½ å·©å›ºæ‰€å­¦ï¼š

### åˆçº§ç»ƒä¹ ï¼ˆå»ºç«‹ä¿¡å¿ƒï¼‰â­
1. **åŸºç¡€æ–‡ä»¶æ“ä½œ** - PCRå®éªŒæ•°æ®è®°å½•
2. **ç®€å•FASTAè§£æ** - æå–åºåˆ—ä¿¡æ¯

### ä¸­çº§ç»ƒä¹ ï¼ˆå®é™…åº”ç”¨ï¼‰â­â­
3. **åºåˆ—è´¨é‡æ§åˆ¶** - è¿‡æ»¤ä½è´¨é‡åºåˆ—
4. **æ‰¹é‡æ–‡ä»¶å¤„ç†** - åˆ†æå¤šä¸ªæ ·æœ¬

### é«˜çº§ç»ƒä¹ ï¼ˆç ”ç©¶çº§åˆ«ï¼‰â­â­â­
5. **æ ¼å¼è½¬æ¢å™¨** - FASTAåˆ°å…¶ä»–æ ¼å¼
6. **å¤§åŸºå› ç»„å¤„ç†** - å†…å­˜ä¼˜åŒ–æŠ€æœ¯

### æŒ‘æˆ˜é¢˜ç›® â­â­â­â­
7. **åºåˆ—æ•°æ®åº“ç³»ç»Ÿ** - æ„å»ºç´¢å¼•å’Œæ£€ç´¢ç³»ç»Ÿ

## ğŸ“Š æœ¬ç« æ€»ç»“

### æ ¸å¿ƒçŸ¥è¯†ç‚¹å›é¡¾

1. **æ–‡ä»¶æ“ä½œæœ¬è´¨**
   - æ–‡ä»¶ = æŒä¹…åŒ–å­˜å‚¨çš„æ•°æ®
   - æ–‡ä»¶ç³»ç»Ÿ = æ•°æ®çš„ç»„ç»‡ç»“æ„
   - è·¯å¾„ = æ–‡ä»¶çš„åœ°å€

2. **æ–‡ä»¶æ“ä½œä¸‰è¦ç´ **
   - æ‰“å¼€ï¼ˆopenï¼‰- å»ºç«‹è¿æ¥
   - æ“ä½œï¼ˆread/writeï¼‰- æ•°æ®äº¤äº’
   - å…³é—­ï¼ˆcloseï¼‰- é‡Šæ”¾èµ„æº

3. **FASTAæ ¼å¼ç²¾é«“**
   - ç®€å•æ€§ï¼šæ–‡æœ¬æ ¼å¼ï¼Œæ˜“è¯»æ˜“å†™
   - é€šç”¨æ€§ï¼šç”Ÿç‰©ä¿¡æ¯å­¦æ ‡å‡†
   - çµæ´»æ€§ï¼šé€‚åº”å„ç§åºåˆ—ç±»å‹

4. **å¤§æ–‡ä»¶å¤„ç†ç­–ç•¥**
   - é€è¡Œè¯»å– vs ä¸€æ¬¡æ€§è¯»å–
   - ç”Ÿæˆå™¨çš„å¨åŠ›
   - å¹¶è¡Œå¤„ç†åŠ é€Ÿ

5. **é”™è¯¯å¤„ç†åŸåˆ™**
   - é¢„æœŸå¸¸è§é”™è¯¯
   - æä¾›æœ‰ç”¨ä¿¡æ¯
   - ä¼˜é›…åœ°å¤±è´¥

### æœ€ä½³å®è·µæ¸…å•

âœ… **å§‹ç»ˆä½¿ç”¨withè¯­å¥ç®¡ç†æ–‡ä»¶**
```python
with open(filename, 'r') as f:
    # æ–‡ä»¶ä¼šè‡ªåŠ¨å…³é—­
```

âœ… **æŒ‡å®šæ–‡ä»¶ç¼–ç **
```python
with open(filename, 'r', encoding='utf-8') as f:
    # é¿å…ç¼–ç é—®é¢˜
```

âœ… **éªŒè¯æ–‡ä»¶å­˜åœ¨æ€§**
```python
if os.path.exists(filename):
    # å®‰å…¨æ“ä½œ
```

âœ… **ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ–‡ä»¶**
```python
def read_sequences():
    yield sequence  # ä¸æ˜¯return
```

âœ… **å®Œæ•´çš„é”™è¯¯å¤„ç†**
```python
try:
    # å°è¯•æ“ä½œ
except SpecificError:
    # å¤„ç†ç‰¹å®šé”™è¯¯
```

### è¿›é˜¶å­¦ä¹ è·¯å¾„

1. **æ·±å…¥å­¦ä¹ Pythonæ ‡å‡†åº“**
   - pathlibï¼šç°ä»£è·¯å¾„æ“ä½œ
   - tempfileï¼šä¸´æ—¶æ–‡ä»¶å¤„ç†
   - shutilï¼šé«˜çº§æ–‡ä»¶æ“ä½œ

2. **æ¢ç´¢ç”Ÿç‰©ä¿¡æ¯å­¦åº“**
   - BioPythonï¼šä¸“ä¸šçš„ç”Ÿç‰©åºåˆ—å¤„ç†
   - pandasï¼šè¡¨æ ¼æ•°æ®å¤„ç†
   - numpyï¼šæ•°å€¼è®¡ç®—

3. **æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯**
   - å¤šè¿›ç¨‹/å¤šçº¿ç¨‹
   - å¼‚æ­¥IO
   - å†…å­˜æ˜ å°„æ–‡ä»¶

## ğŸ¯ å…³é”®è¦ç‚¹

è®°ä½è¿™ä¸‰ä¸ªæ ¸å¿ƒæ¦‚å¿µï¼Œä½ å°±æŒæ¡äº†æ–‡ä»¶IOçš„ç²¾é«“ï¼š

1. **æ–‡ä»¶æ˜¯ä½ çš„æ•°å­—å®éªŒè®°å½•æœ¬** - ç”¨æ¥æ°¸ä¹…ä¿å­˜æ•°æ®
2. **FASTAæ˜¯åºåˆ—çš„é€šç”¨è¯­è¨€** - ç®€å•ã€æ ‡å‡†ã€é€šç”¨
3. **ç”Ÿæˆå™¨æ˜¯å¤„ç†å¤§æ•°æ®çš„ç§˜å¯†æ­¦å™¨** - çœå†…å­˜ã€å¤Ÿä¼˜é›…

## ğŸš€ ä¸‹ä¸€æ­¥

æ­å–œä½ å®Œæˆäº†æ–‡ä»¶IOå’ŒFASTAå¤„ç†çš„å­¦ä¹ ï¼ä½ ç°åœ¨å·²ç»èƒ½å¤Ÿï¼š

- âœ… è‡ªå¦‚åœ°è¯»å†™å„ç§æ–‡ä»¶
- âœ… ä¸“ä¸šåœ°è§£æFASTAæ ¼å¼
- âœ… ä¼˜é›…åœ°å¤„ç†å¤§å‹åŸºå› ç»„æ–‡ä»¶
- âœ… ç¨³å¥åœ°å¤„ç†å„ç§é”™è¯¯æƒ…å†µ

ä¸‹ä¸€ç« ï¼ˆChapter 06ï¼‰ï¼Œæˆ‘ä»¬å°†å­¦ä¹ **Pandasæ•°æ®åˆ†æ**â€”â€”ç”¨Pythonå¤„ç†è¡¨æ ¼æ•°æ®çš„ç»ˆææ­¦å™¨ã€‚ä½ å°†å­¦ä¼šåƒä½¿ç”¨Excelä¸€æ ·è½»æ¾å¤„ç†å¤æ‚çš„ç”Ÿç‰©æ•°æ®è¡¨æ ¼ï¼Œä½†åŠŸèƒ½è¦å¼ºå¤§100å€ï¼

æƒ³è±¡ä¸€ä¸‹ï¼š
- ä¸€è¡Œä»£ç è¯»å–åŒ…å«10ä¸‡ä¸ªåŸºå› è¡¨è¾¾æ•°æ®çš„CSVæ–‡ä»¶
- ç¬é—´è®¡ç®—æ‰€æœ‰æ ·æœ¬çš„ç»Ÿè®¡ä¿¡æ¯
- ä¼˜é›…åœ°åˆå¹¶å¤šä¸ªå®éªŒæ•°æ®è¡¨
- ç”Ÿæˆä¸“ä¸šçš„æ•°æ®å¯è§†åŒ–å›¾è¡¨

å‡†å¤‡å¥½äº†å—ï¼Ÿè®©æˆ‘ä»¬ç»§ç»­è¿™æ®µæ¿€åŠ¨äººå¿ƒçš„æ•°æ®ç§‘å­¦ä¹‹æ—…ï¼

---

*"In biology, nothing makes sense except in the light of data."*  
*"åœ¨ç”Ÿç‰©å­¦ä¸­ï¼Œæ²¡æœ‰æ•°æ®çš„æ”¯æ’‘ï¼Œä¸€åˆ‡éƒ½æ²¡æœ‰æ„ä¹‰ã€‚"*

ç¥å­¦ä¹ æ„‰å¿«ï¼ğŸ§¬ğŸ’»ğŸ“Š