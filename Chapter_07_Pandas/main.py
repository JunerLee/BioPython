#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Chapter 07: Pandasé«˜çº§æ•°æ®åˆ†æ - å®Œæ•´çš„RNA-seqåˆ†ææµç¨‹

ç”Ÿç‰©å­¦é—®é¢˜ï¼šå¦‚ä½•ä»è½¬å½•ç»„æ•°æ®ä¸­å‘ç°ç–¾ç—…ç›¸å…³åŸºå› ï¼Ÿ
ç¼–ç¨‹æ¦‚å¿µï¼šPandasçš„é«˜çº§æ•°æ®æ“ä½œå°±åƒå®éªŒå®¤çš„å¤šé€šé“ç§»æ¶²å™¨ï¼Œèƒ½åŒæ—¶å¤„ç†å¤šä¸ªæ ·æœ¬

æœ¬ç« æ¼”ç¤ºï¼š
1. å¤šå®éªŒæ•°æ®æ•´åˆ - åƒæ•´åˆå¤šä¸ªå®éªŒå®¤çš„æ•°æ®
2. æ‰¹æ¬¡æ•ˆåº”æ ¡æ­£ - æ¶ˆé™¤å®éªŒæ‰¹æ¬¡å¸¦æ¥çš„ç³»ç»Ÿæ€§åå·®
3. ç»Ÿè®¡æ£€éªŒ - ä¸¥æ ¼çš„å‡è®¾æ£€éªŒç¡®ä¿ç»“æœå¯é 
4. æ—¶é—´åºåˆ—åˆ†æ - è¿½è¸ªåŸºå› è¡¨è¾¾çš„åŠ¨æ€å˜åŒ–
5. åŠŸèƒ½åˆ†ç»„åˆ†æ - æŒ‰åŸºå› åŠŸèƒ½æˆ–ä½ç½®åˆ†ç»„ç ”ç©¶
"""

import pandas as pd
import numpy as np
from scipy import stats
from statsmodels.stats.multitest import multipletests
import warnings
warnings.filterwarnings('ignore')


def demonstrate_data_integration():
    """
    æ¼”ç¤ºå¤šä¸ªRNA-seqå®éªŒæ•°æ®çš„æ•´åˆ
    
    ç”Ÿç‰©å­¦ç±»æ¯”ï¼šå°±åƒåˆå¹¶å¤šä¸ªå®éªŒå®¤çš„Western blotç»“æœï¼Œ
    éœ€è¦æ ‡å‡†åŒ–å’Œå¯¹é½æ•°æ®
    """
    print("ğŸ§¬ æ•°æ®æ•´åˆï¼šåˆå¹¶å¤šä¸ªè½¬å½•ç»„å®éªŒ")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿä¸‰ä¸ªä¸åŒå®éªŒçš„æ•°æ®ï¼ˆå¦‚ä¸åŒæ—¶é—´ç‚¹æˆ–ä¸åŒå¤„ç†ï¼‰
    np.random.seed(42)
    genes = [f"GENE_{i:04d}" for i in range(1, 101)]
    
    # å®éªŒ1ï¼šæ—©æœŸæ—¶é—´ç‚¹
    exp1 = pd.DataFrame({
        'gene_id': genes,
        'sample1': np.random.lognormal(8, 1.5, 100),
        'sample2': np.random.lognormal(8, 1.5, 100),
        'sample3': np.random.lognormal(8, 1.5, 100),
        'timepoint': 'T0'
    })
    
    # å®éªŒ2ï¼šä¸­æœŸæ—¶é—´ç‚¹
    exp2 = pd.DataFrame({
        'gene_id': genes,
        'sample1': np.random.lognormal(8.5, 1.5, 100),
        'sample2': np.random.lognormal(8.5, 1.5, 100),
        'sample3': np.random.lognormal(8.5, 1.5, 100),
        'timepoint': 'T6'
    })
    
    # å®éªŒ3ï¼šæ™šæœŸæ—¶é—´ç‚¹
    exp3 = pd.DataFrame({
        'gene_id': genes,
        'sample1': np.random.lognormal(9, 1.5, 100),
        'sample2': np.random.lognormal(9, 1.5, 100),
        'sample3': np.random.lognormal(9, 1.5, 100),
        'timepoint': 'T24'
    })
    
    # åˆå¹¶æ•°æ® - çºµå‘å †å 
    all_data = pd.concat([exp1, exp2, exp3], ignore_index=True)
    
    # æ•°æ®é‡å¡‘ - ä»å®½æ ¼å¼è½¬æ¢ä¸ºé•¿æ ¼å¼
    long_data = pd.melt(all_data, 
                        id_vars=['gene_id', 'timepoint'],
                        value_vars=['sample1', 'sample2', 'sample3'],
                        var_name='sample',
                        value_name='expression')
    
    print("æ•´åˆåçš„æ•°æ®ç»“æ„ï¼ˆå‰10è¡Œï¼‰ï¼š")
    print(long_data.head(10))
    
    # åˆ›å»ºé€è§†è¡¨åˆ†æ
    pivot_table = long_data.pivot_table(
        index='gene_id',
        columns='timepoint',
        values='expression',
        aggfunc='mean'
    )
    
    print("\nåŸºå› è¡¨è¾¾é€è§†è¡¨ï¼ˆå‰5ä¸ªåŸºå› ï¼‰ï¼š")
    print(pivot_table.head().round(2))
    
    return long_data, pivot_table


def perform_differential_expression_analysis():
    """
    æ‰§è¡Œå®Œæ•´çš„å·®å¼‚è¡¨è¾¾åˆ†ææµç¨‹
    
    ç”Ÿç‰©å­¦ç±»æ¯”ï¼šåƒåšqPCRéªŒè¯ï¼Œéœ€è¦å¤šä¸ªæŠ€æœ¯é‡å¤å’Œç”Ÿç‰©å­¦é‡å¤ï¼Œ
    è¿˜è¦è¿›è¡Œç»Ÿè®¡æ£€éªŒç¡®ä¿ç»“æœå¯é 
    """
    print("\nğŸ“Š å·®å¼‚è¡¨è¾¾åˆ†æï¼šè¯†åˆ«ç–¾ç—…ç›¸å…³åŸºå› ")
    print("=" * 60)
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„RNA-seqè®¡æ•°æ•°æ®
    np.random.seed(42)
    n_genes = 500
    gene_ids = [f"GENE_{i:04d}" for i in range(1, n_genes + 1)]
    
    # ç”Ÿæˆå¯¹ç…§ç»„æ•°æ®ï¼ˆ3ä¸ªç”Ÿç‰©å­¦é‡å¤ï¼‰
    control_mean = np.random.lognormal(8, 2, n_genes)
    control_data = np.column_stack([
        np.random.poisson(control_mean * np.random.uniform(0.8, 1.2)) 
        for _ in range(3)
    ])
    
    # ç”Ÿæˆå¤„ç†ç»„æ•°æ®ï¼ˆéƒ¨åˆ†åŸºå› ä¸Šè°ƒæˆ–ä¸‹è°ƒï¼‰
    treatment_mean = control_mean.copy()
    # 20%åŸºå› ä¸Šè°ƒ
    up_genes = np.random.choice(n_genes, size=int(n_genes * 0.2), replace=False)
    treatment_mean[up_genes] *= np.random.uniform(2, 5, len(up_genes))
    # 20%åŸºå› ä¸‹è°ƒ
    down_genes = np.random.choice(
        [i for i in range(n_genes) if i not in up_genes], 
        size=int(n_genes * 0.2), 
        replace=False
    )
    treatment_mean[down_genes] *= np.random.uniform(0.2, 0.5, len(down_genes))
    
    treatment_data = np.column_stack([
        np.random.poisson(treatment_mean * np.random.uniform(0.8, 1.2))
        for _ in range(3)
    ])
    
    # åˆ›å»ºè¡¨è¾¾çŸ©é˜µ
    expression_df = pd.DataFrame({
        'gene_id': gene_ids,
        'control_1': control_data[:, 0],
        'control_2': control_data[:, 1],
        'control_3': control_data[:, 2],
        'treatment_1': treatment_data[:, 0],
        'treatment_2': treatment_data[:, 1],
        'treatment_3': treatment_data[:, 2]
    })
    
    # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    expression_df['control_mean'] = expression_df[['control_1', 'control_2', 'control_3']].mean(axis=1)
    expression_df['treatment_mean'] = expression_df[['treatment_1', 'treatment_2', 'treatment_3']].mean(axis=1)
    expression_df['fold_change'] = expression_df['treatment_mean'] / (expression_df['control_mean'] + 1)  # åŠ 1é¿å…é™¤é›¶
    expression_df['log2_fc'] = np.log2(expression_df['fold_change'] + 0.01)  # åŠ å°å€¼é¿å…log(0)
    
    # æ‰§è¡Œtæ£€éªŒ
    p_values = []
    for i in range(len(expression_df)):
        control_values = expression_df.iloc[i][['control_1', 'control_2', 'control_3']].values
        treatment_values = expression_df.iloc[i][['treatment_1', 'treatment_2', 'treatment_3']].values
        _, p_value = stats.ttest_ind(control_values, treatment_values)
        p_values.append(p_value)
    
    expression_df['p_value'] = p_values
    
    # FDRæ ¡æ­£ï¼ˆæ§åˆ¶å‡é˜³æ€§ï¼‰
    _, fdr_corrected, _, _ = multipletests(expression_df['p_value'].values, 
                                           method='fdr_bh')
    expression_df['fdr'] = fdr_corrected
    
    # ç­›é€‰æ˜¾è‘—å·®å¼‚è¡¨è¾¾åŸºå› 
    sig_threshold = 0.05
    fc_threshold = 2
    
    sig_genes = expression_df[
        (expression_df['fdr'] < sig_threshold) & 
        (np.abs(expression_df['log2_fc']) > np.log2(fc_threshold))
    ].copy()
    
    # åˆ†ç±»ï¼šä¸Šè°ƒå’Œä¸‹è°ƒ
    sig_genes['regulation'] = sig_genes['log2_fc'].apply(
        lambda x: 'up' if x > 0 else 'down'
    )
    
    print(f"æ€»åŸºå› æ•°: {len(expression_df)}")
    print(f"æ˜¾è‘—å·®å¼‚è¡¨è¾¾åŸºå› : {len(sig_genes)}")
    print(f"  - ä¸Šè°ƒ: {len(sig_genes[sig_genes['regulation'] == 'up'])}")
    print(f"  - ä¸‹è°ƒ: {len(sig_genes[sig_genes['regulation'] == 'down'])}")
    
    print("\næœ€æ˜¾è‘—çš„ä¸Šè°ƒåŸºå› ï¼ˆTop 5ï¼‰:")
    top_up = sig_genes[sig_genes['regulation'] == 'up'].nlargest(5, 'log2_fc')
    print(top_up[['gene_id', 'fold_change', 'p_value', 'fdr']].round(4))
    
    print("\næœ€æ˜¾è‘—çš„ä¸‹è°ƒåŸºå› ï¼ˆTop 5ï¼‰:")
    top_down = sig_genes[sig_genes['regulation'] == 'down'].nsmallest(5, 'log2_fc')
    print(top_down[['gene_id', 'fold_change', 'p_value', 'fdr']].round(4))
    
    return expression_df, sig_genes


def analyze_time_series_expression():
    """
    åˆ†æåŸºå› è¡¨è¾¾çš„æ—¶é—´åŠ¨æ€å˜åŒ–
    
    ç”Ÿç‰©å­¦ç±»æ¯”ï¼šå°±åƒè§‚å¯Ÿç»†èƒåˆ†åŒ–è¿‡ç¨‹ä¸­çš„åŸºå› è¡¨è¾¾å˜åŒ–ï¼Œ
    éœ€è¦åœ¨å¤šä¸ªæ—¶é—´ç‚¹é‡‡æ ·å¹¶è¿½è¸ªå˜åŒ–æ¨¡å¼
    """
    print("\nâ° æ—¶é—´åºåˆ—åˆ†æï¼šè¿½è¸ªåŸºå› è¡¨è¾¾åŠ¨æ€")
    print("=" * 60)
    
    # åˆ›å»ºæ—¶é—´åºåˆ—æ•°æ®
    time_points = [0, 2, 4, 6, 8, 12, 24]  # å°æ—¶
    n_genes = 50
    gene_ids = [f"GENE_{i:04d}" for i in range(1, n_genes + 1)]
    
    # ç”Ÿæˆä¸åŒè¡¨è¾¾æ¨¡å¼çš„åŸºå› 
    expression_patterns = []
    pattern_types = []
    
    for i in range(n_genes):
        if i < 10:  # æ—©æœŸå“åº”åŸºå› 
            pattern = np.array([100 * np.exp(-t/5) + 20 for t in time_points])
            pattern_types.append('early_response')
        elif i < 20:  # æ™šæœŸå“åº”åŸºå› 
            pattern = np.array([20 + 80 * (1 - np.exp(-t/10)) for t in time_points])
            pattern_types.append('late_response')
        elif i < 30:  # å‘¨æœŸæ€§åŸºå› 
            pattern = np.array([50 + 30 * np.sin(t * np.pi / 12) for t in time_points])
            pattern_types.append('oscillating')
        else:  # ç¨³å®šè¡¨è¾¾åŸºå› 
            pattern = np.array([50 + np.random.normal(0, 5, len(time_points))])
            pattern_types.append('stable')
        
        # æ·»åŠ å™ªå£°
        pattern = pattern * np.random.uniform(0.9, 1.1, len(time_points))
        expression_patterns.append(pattern)
    
    # åˆ›å»ºæ—¶é—´åºåˆ—DataFrame
    time_series_data = pd.DataFrame(expression_patterns, 
                                   columns=[f'T{t}h' for t in time_points])
    time_series_data['gene_id'] = gene_ids
    time_series_data['pattern_type'] = pattern_types
    
    # é‡æ–°æ’åˆ—åˆ—
    cols = ['gene_id', 'pattern_type'] + [f'T{t}h' for t in time_points]
    time_series_data = time_series_data[cols]
    
    # è®¡ç®—æ—¶é—´åºåˆ—ç»Ÿè®¡
    time_cols = [f'T{t}h' for t in time_points]
    time_series_data['mean_expression'] = time_series_data[time_cols].mean(axis=1)
    time_series_data['std_expression'] = time_series_data[time_cols].std(axis=1)
    time_series_data['cv'] = (time_series_data['std_expression'] / 
                              time_series_data['mean_expression'])
    
    # è®¡ç®—æœ€å¤§å˜åŒ–å¹…åº¦
    time_series_data['max_change'] = (time_series_data[time_cols].max(axis=1) - 
                                      time_series_data[time_cols].min(axis=1))
    
    print("æ—¶é—´åºåˆ—æ•°æ®æ¦‚è§ˆï¼š")
    print(time_series_data.groupby('pattern_type').agg({
        'mean_expression': 'mean',
        'cv': 'mean',
        'max_change': 'mean'
    }).round(2))
    
    print("\né«˜å˜å¼‚åŸºå› ï¼ˆCV > 0.3ï¼‰ï¼š")
    high_var_genes = time_series_data[time_series_data['cv'] > 0.3]
    print(high_var_genes[['gene_id', 'pattern_type', 'cv', 'max_change']].head(10).round(3))
    
    # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µï¼ˆæ‰¾å‡ºç›¸ä¼¼è¡¨è¾¾æ¨¡å¼çš„åŸºå› ï¼‰
    correlation_matrix = time_series_data[time_cols].T.corr()
    
    print("\nåŸºå› è¡¨è¾¾ç›¸å…³æ€§åˆ†æï¼š")
    print(f"ç›¸å…³æ€§çŸ©é˜µå¤§å°: {correlation_matrix.shape}")
    
    # æ‰¾å‡ºé«˜åº¦ç›¸å…³çš„åŸºå› å¯¹
    high_corr_pairs = []
    for i in range(len(correlation_matrix)):
        for j in range(i+1, len(correlation_matrix)):
            if abs(correlation_matrix.iloc[i, j]) > 0.9:
                high_corr_pairs.append({
                    'gene1': gene_ids[i],
                    'gene2': gene_ids[j],
                    'correlation': correlation_matrix.iloc[i, j]
                })
    
    if high_corr_pairs:
        high_corr_df = pd.DataFrame(high_corr_pairs).head(5)
        print(f"é«˜åº¦ç›¸å…³çš„åŸºå› å¯¹ï¼ˆ|r| > 0.9ï¼Œå‰5å¯¹ï¼‰ï¼š")
        print(high_corr_df.round(3))
    
    return time_series_data


def perform_functional_grouping_analysis():
    """
    æŒ‰åŸºå› åŠŸèƒ½æˆ–æŸ“è‰²ä½“ä½ç½®è¿›è¡Œåˆ†ç»„åˆ†æ
    
    ç”Ÿç‰©å­¦ç±»æ¯”ï¼šå°±åƒå°†åŸºå› æŒ‰ç…§GOåŠŸèƒ½åˆ†ç±»æˆ–æŒ‰æŸ“è‰²ä½“ä½ç½®åˆ†ç»„ï¼Œ
    ç ”ç©¶ä¸åŒåŠŸèƒ½æ¨¡å—æˆ–åŸºå› ç»„åŒºåŸŸçš„è¡¨è¾¾ç‰¹å¾
    """
    print("\nğŸ”¬ åŠŸèƒ½åˆ†ç»„åˆ†æï¼šç ”ç©¶åŸºå› åŠŸèƒ½æ¨¡å—")
    print("=" * 60)
    
    # åˆ›å»ºåŸºå› æ³¨é‡Šæ•°æ®
    np.random.seed(42)
    n_genes = 200
    gene_ids = [f"GENE_{i:04d}" for i in range(1, n_genes + 1)]
    
    # æ¨¡æ‹ŸåŸºå› åŠŸèƒ½åˆ†ç±»
    functions = ['metabolism', 'cell_cycle', 'immune_response', 
                'transcription', 'signal_transduction']
    gene_functions = np.random.choice(functions, n_genes)
    
    # æ¨¡æ‹ŸæŸ“è‰²ä½“ä½ç½®
    chromosomes = [f'chr{i}' for i in range(1, 23)] + ['chrX', 'chrY']
    gene_chromosomes = np.random.choice(chromosomes[:10], n_genes)  # ä½¿ç”¨å‰10æ¡æŸ“è‰²ä½“
    
    # æ¨¡æ‹ŸåŸºå› è¡¨è¾¾æ•°æ®ï¼ˆä¸åŒåŠŸèƒ½çš„åŸºå› æœ‰ä¸åŒçš„è¡¨è¾¾æ¨¡å¼ï¼‰
    expression_data = []
    for func in gene_functions:
        if func == 'metabolism':
            expr = np.random.lognormal(8, 1)
        elif func == 'cell_cycle':
            expr = np.random.lognormal(7, 1.5)
        elif func == 'immune_response':
            expr = np.random.lognormal(6, 2)
        elif func == 'transcription':
            expr = np.random.lognormal(9, 0.5)
        else:  # signal_transduction
            expr = np.random.lognormal(7.5, 1)
        expression_data.append(expr)
    
    # åˆ›å»ºç»¼åˆæ•°æ®æ¡†
    gene_annotation_df = pd.DataFrame({
        'gene_id': gene_ids,
        'function': gene_functions,
        'chromosome': gene_chromosomes,
        'expression': expression_data,
        'length': np.random.randint(500, 5000, n_genes)  # åŸºå› é•¿åº¦
    })
    
    # æŒ‰åŠŸèƒ½åˆ†ç»„åˆ†æ
    print("æŒ‰åŠŸèƒ½åˆ†ç»„çš„è¡¨è¾¾åˆ†æï¼š")
    function_stats = gene_annotation_df.groupby('function').agg({
        'expression': ['mean', 'std', 'count'],
        'length': 'mean'
    }).round(2)
    function_stats.columns = ['_'.join(col).strip() for col in function_stats.columns]
    print(function_stats)
    
    # æŒ‰æŸ“è‰²ä½“åˆ†ç»„åˆ†æ
    print("\næŒ‰æŸ“è‰²ä½“åˆ†ç»„çš„åŸºå› åˆ†å¸ƒï¼š")
    chr_stats = gene_annotation_df.groupby('chromosome').agg({
        'gene_id': 'count',
        'expression': 'mean',
        'length': 'sum'
    }).rename(columns={'gene_id': 'gene_count', 
                       'expression': 'mean_expression',
                       'length': 'total_length'})
    chr_stats = chr_stats.sort_values('gene_count', ascending=False).head(5)
    print(chr_stats.round(2))
    
    # åŠŸèƒ½å¯Œé›†åˆ†æï¼ˆæ¨¡æ‹Ÿï¼‰
    print("\nåŠŸèƒ½å¯Œé›†åˆ†æï¼ˆæ¨¡æ‹Ÿè¶…å‡ ä½•æ£€éªŒï¼‰ï¼š")
    # å‡è®¾æˆ‘ä»¬æœ‰ä¸€ç»„å·®å¼‚è¡¨è¾¾åŸºå› 
    n_deg = 50  # å·®å¼‚è¡¨è¾¾åŸºå› æ•°
    deg_indices = np.random.choice(n_genes, n_deg, replace=False)
    deg_functions = gene_annotation_df.iloc[deg_indices]['function'].value_counts()
    
    enrichment_results = []
    for func in functions:
        n_func_in_deg = deg_functions.get(func, 0)
        n_func_total = (gene_annotation_df['function'] == func).sum()
        # ç®€åŒ–çš„å¯Œé›†åˆ†æ•°è®¡ç®—
        enrichment_score = (n_func_in_deg / n_deg) / (n_func_total / n_genes)
        enrichment_results.append({
            'function': func,
            'genes_in_DEG': n_func_in_deg,
            'genes_total': n_func_total,
            'enrichment_score': enrichment_score
        })
    
    enrichment_df = pd.DataFrame(enrichment_results)
    enrichment_df = enrichment_df.sort_values('enrichment_score', ascending=False)
    print(enrichment_df.round(3))
    
    return gene_annotation_df, enrichment_df


def demonstrate_advanced_operations():
    """
    æ¼”ç¤ºå…¶ä»–é«˜çº§Pandasæ“ä½œ
    
    åŒ…æ‹¬ï¼šçª—å£å‡½æ•°ã€æ•°æ®é€è§†ã€å¤šçº§ç´¢å¼•ç­‰
    """
    print("\nğŸ¯ é«˜çº§æ•°æ®æ“ä½œæŠ€å·§")
    print("=" * 60)
    
    # åˆ›å»ºå¤šçº§ç´¢å¼•æ•°æ®
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿå¤šä¸ªå®éªŒæ¡ä»¶çš„æ•°æ®
    conditions = ['control', 'treatment_A', 'treatment_B']
    replicates = ['rep1', 'rep2', 'rep3']
    genes = [f'GENE_{i:03d}' for i in range(1, 21)]
    
    # åˆ›å»ºå¤šçº§ç´¢å¼•
    index = pd.MultiIndex.from_product([conditions, replicates], 
                                      names=['condition', 'replicate'])
    
    # ç”Ÿæˆè¡¨è¾¾æ•°æ®
    data = np.random.lognormal(8, 1, (9, 20))
    multi_index_df = pd.DataFrame(data, index=index, columns=genes)
    
    print("å¤šçº§ç´¢å¼•æ•°æ®ç»“æ„ï¼š")
    print(multi_index_df.head())
    
    # ä½¿ç”¨groupbyå’Œtransform
    print("\nè®¡ç®—æ¯ä¸ªæ¡ä»¶çš„z-scoreæ ‡å‡†åŒ–ï¼š")
    # æŒ‰æ¡ä»¶åˆ†ç»„ï¼Œè®¡ç®—z-score
    zscore_df = multi_index_df.groupby(level='condition').transform(
        lambda x: (x - x.mean()) / x.std()
    )
    print(zscore_df.head().round(2))
    
    # æ»‘åŠ¨çª—å£è®¡ç®—
    print("\næ»‘åŠ¨çª—å£åˆ†æï¼ˆæ¨¡æ‹Ÿæ—¶é—´åºåˆ—ï¼‰ï¼š")
    time_series = pd.Series(np.random.randn(20).cumsum(), 
                           index=pd.date_range('2024-01-01', periods=20))
    
    # è®¡ç®—3å¤©ç§»åŠ¨å¹³å‡
    rolling_mean = time_series.rolling(window=3).mean()
    rolling_std = time_series.rolling(window=3).std()
    
    result_df = pd.DataFrame({
        'original': time_series,
        'rolling_mean': rolling_mean,
        'rolling_std': rolling_std
    })
    print(result_df.tail(10).round(3))
    
    return multi_index_df


def main():
    """
    ä¸»å‡½æ•° - å®Œæ•´çš„RNA-seqæ•°æ®åˆ†ææµç¨‹
    """
    print("=" * 70)
    print("Chapter 07: Pandasé«˜çº§æ•°æ®åˆ†æ - å®Œæ•´RNA-seqåˆ†ææµç¨‹")
    print("=" * 70)
    print("\nä»åŸå§‹æ•°æ®åˆ°ç”Ÿç‰©å­¦å‘ç°çš„å®Œæ•´åˆ†æç®¡é“\n")
    
    # 1. æ•°æ®æ•´åˆ
    long_data, pivot_table = demonstrate_data_integration()
    
    # 2. å·®å¼‚è¡¨è¾¾åˆ†æ
    expression_df, sig_genes = perform_differential_expression_analysis()
    
    # 3. æ—¶é—´åºåˆ—åˆ†æ
    time_series_data = analyze_time_series_expression()
    
    # 4. åŠŸèƒ½åˆ†ç»„åˆ†æ
    gene_annotation_df, enrichment_df = perform_functional_grouping_analysis()
    
    # 5. é«˜çº§æ“ä½œæ¼”ç¤º
    multi_index_df = demonstrate_advanced_operations()
    
    # æ€»ç»“
    print("\n" + "=" * 70)
    print("ğŸ“Š æœ¬ç« æ ¸å¿ƒè¦ç‚¹æ€»ç»“")
    print("=" * 70)
    
    print("""
    1. æ•°æ®æ•´åˆï¼šå¤šä¸ªå®éªŒæ•°æ®çš„æ ‡å‡†åŒ–åˆå¹¶
       - ä½¿ç”¨concatã€mergeã€joinæ•´åˆæ•°æ®
       - æ•°æ®é‡å¡‘ï¼špivotã€meltã€stack/unstack
    
    2. ç»Ÿè®¡åˆ†æï¼šä¸¥æ ¼çš„å‡è®¾æ£€éªŒæµç¨‹
       - tæ£€éªŒè¯†åˆ«å·®å¼‚è¡¨è¾¾
       - FDRæ ¡æ­£æ§åˆ¶å‡é˜³æ€§
       - æ•ˆåº”å¤§å°ï¼ˆfold changeï¼‰è¯„ä¼°ç”Ÿç‰©å­¦æ„ä¹‰
    
    3. æ—¶é—´åºåˆ—ï¼šåŠ¨æ€è¡¨è¾¾æ¨¡å¼åˆ†æ
       - è¯†åˆ«æ—©æœŸ/æ™šæœŸå“åº”åŸºå› 
       - ç›¸å…³æ€§åˆ†ææ‰¾å‡ºå…±è¡¨è¾¾åŸºå› 
       - å˜å¼‚ç³»æ•°è¯„ä¼°è¡¨è¾¾ç¨³å®šæ€§
    
    4. åŠŸèƒ½åˆ†æï¼šåŸºå› åŠŸèƒ½æ¨¡å—ç ”ç©¶
       - æŒ‰åŠŸèƒ½æˆ–ä½ç½®åˆ†ç»„
       - å¯Œé›†åˆ†æè¯†åˆ«å…³é”®é€šè·¯
       - å¤šç»´åº¦æ•°æ®æ•´åˆ
    
    5. é«˜çº§æŠ€å·§ï¼š
       - å¤šçº§ç´¢å¼•å¤„ç†å¤æ‚å®éªŒè®¾è®¡
       - çª—å£å‡½æ•°è¿›è¡Œå±€éƒ¨åˆ†æ
       - å‘é‡åŒ–æ“ä½œæå‡æ€§èƒ½
    """)
    
    print("\nğŸ’¡ ç”Ÿç‰©å­¦æ´å¯Ÿï¼š")
    print("   é€šè¿‡ç³»ç»Ÿçš„æ•°æ®åˆ†æï¼Œæˆ‘ä»¬å¯ä»¥ï¼š")
    print("   â€¢ è¯†åˆ«ç–¾ç—…ç›¸å…³çš„å…³é”®åŸºå› ")
    print("   â€¢ ç†è§£åŸºå› è¡¨è¾¾çš„æ—¶ç©ºåŠ¨æ€")
    print("   â€¢ å‘ç°åŠŸèƒ½ç›¸å…³çš„åŸºå› æ¨¡å—")
    print("   â€¢ ä¸ºåç»­å®éªŒéªŒè¯æä¾›å€™é€‰é¶ç‚¹")
    
    print("\nğŸš€ ä¸‹ä¸€æ­¥ï¼šå­¦ä¹ æ•°æ®å¯è§†åŒ–ï¼Œå°†è¿™äº›åˆ†æç»“æœè½¬åŒ–ä¸ºç›´è§‚çš„å›¾è¡¨ï¼")


if __name__ == "__main__":
    main()